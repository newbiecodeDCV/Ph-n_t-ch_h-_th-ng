# HÆ°á»›ng dáº«n Äáº§y Ä‘á»§: ÄÃ¡nh giÃ¡ Tá»‘c Ä‘á»™ NÃ³i (Speech Rate Evaluation)

**PhiÃªn báº£n:** v1.0 - Tá»•ng há»£p tá»« tÃ i liá»‡u chuáº©n  
**Má»¥c Ä‘Ã­ch:** TÃ³m táº¯t hoÃ n chá»‰nh quy trÃ¬nh Ä‘Ã¡nh giÃ¡ tá»‘c Ä‘á»™ nÃ³i nhanh/cháº­m cá»§a Agent trong há»‡ thá»‘ng AI QA Call

---

## ğŸ“‹ Tá»•ng quan

### Vá»‹ trÃ­ trong há»‡ thá»‘ng cháº¥m Ä‘iá»ƒm

```
TiÃªu chÃ­: A.2 - Ká»¹ nÄƒng nÃ³i (10% Ä‘iá»ƒm KNGT)
â”œâ”€ A.2.1 Tá»‘c Ä‘á»™ nÃ³i (1/3 cá»§a 10% KNGT)
â”œâ”€ A.2.2 Ã‚m lÆ°á»£ng (1/3 cá»§a 10% KNGT)
â””â”€ A.2.3 Äá»™ rÃµ phÃ¡t Ã¢m (1/3 cá»§a 10% KNGT)

Äiá»ƒm quy Ä‘á»•i:
- BH: 10% Ã— 2.0 (KNGT) Ã— 1/3 = 0.067 Ä‘iá»ƒm
- CSKH: 10% Ã— 4.0 (KNGT) Ã— 1/3 = 0.133 Ä‘iá»ƒm
```

### Má»©c Ä‘á»™ áº£nh hÆ°á»Ÿng

| Má»©c lá»—i | Trá»« Ä‘iá»ƒm | VÃ­ dá»¥ |
|---------|----------|-------|
| **M1** | ÄÃºng Ä‘iá»ƒm tiÃªu chÃ­ con | Agent nÃ³i hÆ¡i nhanh/cháº­m nhÆ°ng KH váº«n theo ká»‹p |
| **M2** | Trá»« 50% Ä‘iá»ƒm NHÃ“M KNGT | KH yÃªu cáº§u nháº¯c láº¡i â‰¥3 láº§n do nÃ³i quÃ¡ nhanh/cháº­m |
| **M3** | Äiá»ƒm NHÃ“M KNGT = 0 | GÃ¢y hiá»ƒu sai ná»™i dung quan trá»ng (OTP, Ä‘iá»u khoáº£n) |

---

## ğŸ¯ Pipeline Äáº§y Ä‘á»§ (10 BÆ°á»›c)

### BÆ°á»›c 1: Chuáº©n bá»‹ Input

**Input cáº§n cÃ³:**
```
âœ“ Audio file (mono, 16kHz)
âœ“ Call metadata (call_id, agent_id, call_time, team)
```

**Tools:**
- STT: Whisper / Google Cloud STT / Azure Speech
- Diarization: pyannote.audio / AWS Transcribe
- VAD: webrtcvad / silero-vad

**Output BÆ°á»›c 1:**
```json
{
  "audio_path": "call_12345.wav",
  "call_id": "12345",
  "agent_id": "AGENT_001",
  "team": "Sales_BH",
  "duration_total": 300.0
}
```

**Thá»i gian:** Chuáº©n bá»‹ tá»©c thÃ¬

---

### BÆ°á»›c 2: Speech-to-Text (STT)

**Má»¥c Ä‘Ã­ch:** Chuyá»ƒn audio â†’ text vá»›i timestamps

**Input:** Audio file  
**Process:**
```python
import whisper

model = whisper.load_model("large-v2")
result = model.transcribe(
    "call_12345.wav",
    language="vi",
    word_timestamps=True  # â† QUAN TRá»ŒNG!
)
```

**Output:**
```json
{
  "text": "Em xin chÃ o anh áº¡...",
  "segments": [...],
  "words": [
    {"word": "Em", "start": 0.0, "end": 0.2},
    {"word": "xin", "start": 0.2, "end": 0.4},
    ...
  ]
}
```

**Thá»i gian:** 2-5 giÃ¢y cho 5 phÃºt audio

---

### BÆ°á»›c 3: Diarization (PhÃ¢n ngÆ°á»i nÃ³i)

**Má»¥c Ä‘Ã­ch:** TÃ¡ch AGENT vs CUSTOMER

**Input:** Audio + Transcript  
**Process:**
```python
from pyannote.audio import Pipeline

pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization")
diarization = pipeline("call_12345.wav", num_speakers=2)

# Gáº¯n nhÃ£n AGENT/CUSTOMER
labeled_segments = label_speakers(diarization, transcript)
```

**Output:**
```json
[
  {
    "speaker": "AGENT",
    "start": 0.0,
    "end": 8.5,
    "text": "Em xin chÃ o anh áº¡, em lÃ  Hoa",
    "words": [...]
  },
  {
    "speaker": "CUSTOMER",
    "start": 9.0,
    "end": 11.2,
    "text": "ChÃ o em"
  },
  ...
]
```

**Thá»i gian:** 1-3 giÃ¢y

---

### BÆ°á»›c 4: VAD (Voice Activity Detection)

**Má»¥c Ä‘Ã­ch:** PhÃ¡t hiá»‡n Ä‘Ã¢u lÃ  nÃ³i (voiced), Ä‘Ã¢u lÃ  im láº·ng (silence)

**Input:** Audio file  
**Process:**
```python
import webrtcvad
import numpy as np

vad = webrtcvad.Vad(2)  # aggressiveness level 2
vad_array = compute_vad(audio_data, sample_rate=16000, frame_ms=10)

# Output: array nhá»‹ phÃ¢n
# vad_array = [1, 1, 1, 0, 0, 1, 1, ...] @ 10ms resolution
#              â†‘           â†‘
#           voiced     silence
```

**Output:**
```python
# Numpy array, má»—i pháº§n tá»­ = 10ms
vad_array = np.array([1, 1, 1, ..., 0, 0, ..., 1, 1, 1])
# Shape: (30000,) cho audio 5 phÃºt (300s / 0.01s = 30000 frames)
```

**Thá»i gian:** 0.5-1 giÃ¢y â† **Ráº¤T NHANH, KHÃ”NG GÃ‚Y TRá»„!**

---

### BÆ°á»›c 5: Chia Segments theo Speaker

**Má»¥c Ä‘Ã­ch:** TÃ¡ch riÃªng tá»«ng lÆ°á»£t nÃ³i cá»§a AGENT

**Input:** Diarization output  
**Process:** Lá»c láº¥y `speaker == "AGENT"`

**Output:**
```json
[
  {
    "segment_id": "S1",
    "speaker": "AGENT",
    "start": 0.0,
    "end": 8.5,
    "duration": 8.5,
    "text": "Em xin chÃ o anh áº¡...",
    "words": [...]
  },
  {
    "segment_id": "S3",
    "speaker": "AGENT",
    "start": 12.0,
    "end": 45.8,  â† Segment dÃ i! (33.8s)
    "duration": 33.8,
    "text": "Em lÃ  Hoa tá»« cÃ´ng ty ABC...",
    "words": [...]
  },
  ...
]
```

**Thá»i gian:** <0.1 giÃ¢y

---

### BÆ°á»›c 6: Chia Segments DÃ i theo Pause

**Má»¥c Ä‘Ã­ch:** Chia segment >15s thÃ nh cÃ¡c sub-segments nhá» hÆ¡n

**Quy táº¯c:**
```
IF segment.duration > 15s:
    - TÃ¬m pause dÃ i â‰¥700ms trong segment
    - Chia táº¡i cÃ¡c pause
    - Táº¡o sub-segments
ELSE:
    - Giá»¯ nguyÃªn
```

#### 6.1. TÃ¬m Pause

**Input:** VAD array + segment boundaries  
**Process:**
```python
def find_pauses(start_sec, end_sec, vad_array, threshold_ms=700):
    """
    TÃ¬m cÃ¡c Ä‘oáº¡n im láº·ng â‰¥700ms
    
    Returns:
        [(pause_start, pause_end), ...]
    """
    frame_duration = 0.01  # 10ms
    threshold_sec = threshold_ms / 1000.0
    
    # Láº¥y pháº§n VAD tÆ°Æ¡ng á»©ng segment
    start_frame = int(start_sec / frame_duration)
    end_frame = int(end_sec / frame_duration)
    vad_segment = vad_array[start_frame:end_frame]
    
    pauses = []
    in_pause = False
    pause_start_frame = 0
    
    for i, is_voiced in enumerate(vad_segment):
        if is_voiced == 0:  # Silence
            if not in_pause:
                in_pause = True
                pause_start_frame = i
        else:  # Voiced
            if in_pause:
                pause_duration = (i - pause_start_frame) * frame_duration
                if pause_duration >= threshold_sec:
                    pause_start = start_sec + pause_start_frame * frame_duration
                    pause_end = start_sec + i * frame_duration
                    pauses.append((pause_start, pause_end))
                in_pause = False
    
    return pauses

# VÃ­ dá»¥
pauses = find_pauses(12.0, 45.8, vad_array, threshold_ms=700)
# Output: [(18.5, 19.2), (28.7, 30.1)]
```

#### 6.2. Chia Segment

**Input:** Segment + pause positions  
**Process:**

**CÃ¡ch 1: Chia text theo tá»· lá»‡ thá»i gian** (ÄÆ¡n giáº£n, 85-90% accuracy)
```python
def split_text_by_duration_ratio(segment, pauses):
    """
    Chia text theo tá»· lá»‡ thá»i lÆ°á»£ng
    """
    words = segment["text"].split()
    total_duration = segment["duration"]
    
    sub_segments = []
    current_start = segment["start"]
    words_used = 0
    
    for pause_start, pause_end in pauses:
        sub_duration = pause_start - current_start
        ratio = sub_duration / total_duration
        word_count = round(len(words) * ratio)
        
        sub_text = " ".join(words[words_used:words_used + word_count])
        
        sub_seg = {
            "segment_id": f"{segment['segment_id']}_split",
            "speaker": "AGENT",
            "start": current_start,
            "end": pause_start,
            "duration": sub_duration,
            "text": sub_text,
            "word_count": word_count
        }
        sub_segments.append(sub_seg)
        
        current_start = pause_end
        words_used += word_count
    
    # Sub-segment cuá»‘i cÃ¹ng
    final_seg = {
        "segment_id": f"{segment['segment_id']}_split",
        "speaker": "AGENT",
        "start": current_start,
        "end": segment["end"],
        "duration": segment["end"] - current_start,
        "text": " ".join(words[words_used:]),
        "word_count": len(words) - words_used
    }
    sub_segments.append(final_seg)
    
    return sub_segments
```

**CÃ¡ch 2: Chia text theo word timestamps** (ChÃ­nh xÃ¡c 100%)
```python
def split_text_by_word_timestamps(words_with_timestamps, pause_positions):
    """
    Chia text dá»±a trÃªn timestamps tá»«ng tá»«
    """
    sub_segments = []
    current_words = []
    current_start = words_with_timestamps[0]["start"]
    pause_idx = 0
    
    for word_obj in words_with_timestamps:
        word_end = word_obj["end"]
        
        # Kiá»ƒm tra vÆ°á»£t pause?
        if pause_idx < len(pause_positions) and word_end >= pause_positions[pause_idx]:
            # Káº¿t thÃºc sub-segment hiá»‡n táº¡i
            sub_seg = {
                "start": current_start,
                "end": pause_positions[pause_idx],
                "text": " ".join(current_words),
                "word_count": len(current_words)
            }
            sub_segments.append(sub_seg)
            
            # Báº¯t Ä‘áº§u sub-segment má»›i
            current_words = [word_obj["word"]]
            current_start = word_obj["start"]
            pause_idx += 1
        else:
            current_words.append(word_obj["word"])
    
    # Sub-segment cuá»‘i
    if current_words:
        sub_seg = {
            "start": current_start,
            "end": words_with_timestamps[-1]["end"],
            "text": " ".join(current_words),
            "word_count": len(current_words)
        }
        sub_segments.append(sub_seg)
    
    return sub_segments
```

**Output:**
```json
[
  {
    "segment_id": "S3_split_1",
    "speaker": "AGENT",
    "start": 12.0,
    "end": 18.5,
    "duration": 6.5,
    "text": "Em lÃ  Hoa tá»« cÃ´ng ty ABC",
    "word_count": 7
  },
  {
    "segment_id": "S3_split_2",
    "speaker": "AGENT",
    "start": 19.2,
    "end": 28.7,
    "duration": 9.5,
    "text": "Hiá»‡n táº¡i cÃ´ng ty em Ä‘ang cÃ³ chÆ°Æ¡ng trÃ¬nh...",
    "word_count": 15
  },
  {
    "segment_id": "S3_split_3",
    "speaker": "AGENT",
    "start": 30.1,
    "end": 45.8,
    "duration": 15.7,
    "text": "Anh cÃ³ quan tÃ¢m Ä‘áº¿n sáº£n pháº©m báº£o hiá»ƒm...",
    "word_count": 18
  }
]
```

**Thá»i gian:** 0.1 giÃ¢y

---

### BÆ°á»›c 7: TÃ­nh Voiced Duration cho tá»«ng Segment

**Má»¥c Ä‘Ã­ch:** Loáº¡i bá» im láº·ng, chá»‰ giá»¯ thá»i lÆ°á»£ng phÃ¡t Ã¢m thá»±c táº¿

**Input:** Segments + VAD array  
**Process:**
```python
def calculate_voiced_duration(segment, vad_array):
    """
    TÃ­nh thá»i lÆ°á»£ng phÃ¡t Ã¢m thá»±c táº¿ (loáº¡i im láº·ng)
    """
    frame_duration = 0.01  # 10ms
    
    start_frame = int(segment["start"] / frame_duration)
    end_frame = int(segment["end"] / frame_duration)
    vad_segment = vad_array[start_frame:end_frame]
    
    voiced_frames = np.sum(vad_segment == 1)
    voiced_duration = voiced_frames * frame_duration
    
    return voiced_duration

# Ãp dá»¥ng cho táº¥t cáº£ segments
for seg in segments:
    seg["voiced_duration"] = calculate_voiced_duration(seg, vad_array)
```

**Output:**
```json
{
  "segment_id": "S3_split_1",
  "duration": 6.5,
  "voiced_duration": 6.1,  â† Loáº¡i bá» 0.4s im láº·ng
  "text": "Em lÃ  Hoa tá»« cÃ´ng ty ABC",
  "word_count": 7
}
```

**Thá»i gian:** 0.1 giÃ¢y

---

### BÆ°á»›c 8: TÃ­nh Articulation Rate (WPM) cho tá»«ng Segment

**CÃ´ng thá»©c:**
```
wpm_segment = 60 Ã— word_count / voiced_duration_seconds
```

**LÃ½ do dÃ¹ng Articulation Rate (khÃ´ng pháº£i Speaking Rate):**
- âœ… CÃ´ng báº±ng vá»›i Agent dá»«ng há»£p lÃ½
- âœ… TÃ¡ch biá»‡t "tá»‘c Ä‘á»™ phÃ¡t Ã¢m" vs "quáº£n lÃ½ nhá»‹p cuá»™c gá»i"
- âœ… á»”n Ä‘á»‹nh hÆ¡n giá»¯a cÃ¡c cuá»™c gá»i

**Process:**
```python
def calculate_wpm_for_segments(segments):
    """
    TÃ­nh WPM cho má»—i segment cá»§a AGENT
    """
    wpm_results = []
    
    for seg in segments:
        if seg["speaker"] != "AGENT":
            continue
        
        if seg["voiced_duration"] < 1.0:  # QuÃ¡ ngáº¯n, bá» qua
            continue
        
        wpm = 60.0 * seg["word_count"] / seg["voiced_duration"]
        
        wpm_results.append({
            "segment_id": seg["segment_id"],
            "start": seg["start"],
            "end": seg["end"],
            "duration": seg["duration"],
            "voiced_duration": seg["voiced_duration"],
            "word_count": seg["word_count"],
            "wpm": wpm,
            "text_preview": seg["text"][:50]
        })
    
    return wpm_results

# VÃ­ dá»¥
wpm_results = calculate_wpm_for_segments(segments)
```

**Output:**
```json
[
  {
    "segment_id": "S1",
    "start": 0.0,
    "end": 8.5,
    "duration": 8.5,
    "voiced_duration": 8.1,
    "word_count": 12,
    "wpm": 88.9,  â† 60 Ã— 12 / 8.1
    "text_preview": "Em xin chÃ o anh áº¡, em lÃ  Hoa Ä‘Ã¢y áº¡"
  },
  {
    "segment_id": "S3_split_1",
    "start": 12.0,
    "end": 18.5,
    "duration": 6.5,
    "voiced_duration": 6.1,
    "word_count": 7,
    "wpm": 68.9,  â† Cháº­m
    "text_preview": "Em lÃ  Hoa tá»« cÃ´ng ty ABC"
  },
  {
    "segment_id": "S3_split_2",
    "start": 19.2,
    "end": 28.7,
    "duration": 9.5,
    "voiced_duration": 9.2,
    "word_count": 15,
    "wpm": 97.8,  â† BÃ¬nh thÆ°á»ng
    "text_preview": "Hiá»‡n táº¡i cÃ´ng ty em Ä‘ang cÃ³ chÆ°Æ¡ng trÃ¬nh..."
  },
  {
    "segment_id": "S5",
    "start": 50.0,
    "end": 65.3,
    "duration": 15.3,
    "voiced_duration": 14.8,
    "word_count": 48,
    "wpm": 194.6,  â† Ráº¤T NHANH! VÆ°á»£t ngÆ°á»¡ng
    "text_preview": "Anh quan tÃ¢m sáº£n pháº©m báº£o hiá»ƒm nhÃ¢n thá» khÃ´ng..."
  }
]
```

**Thá»i gian:** 0.2 giÃ¢y

---

### BÆ°á»›c 9: Tá»•ng há»£p Metrics vÃ  So sÃ¡nh Baseline

**Má»¥c Ä‘Ã­ch:** TÃ­nh cÃ¡c chá»‰ sá»‘ thá»‘ng kÃª vÃ  so vá»›i baseline team

#### 9.1. TÃ­nh Metrics Tá»•ng há»£p

```python
def aggregate_metrics(wpm_results):
    """
    TÃ­nh cÃ¡c chá»‰ sá»‘ thá»‘ng kÃª
    """
    wpm_values = [r["wpm"] for r in wpm_results]
    
    metrics = {
        "median_wpm": np.median(wpm_values),
        "mean_wpm": np.mean(wpm_values),
        "std_wpm": np.std(wpm_values),
        "p10_wpm": np.percentile(wpm_values, 10),
        "p90_wpm": np.percentile(wpm_values, 90),
        "min_wpm": np.min(wpm_values),
        "max_wpm": np.max(wpm_values),
        "total_segments": len(wpm_values)
    }
    
    return metrics

metrics = aggregate_metrics(wpm_results)
# Output: {
#   "median_wpm": 145.3,
#   "mean_wpm": 148.7,
#   "p90_wpm": 192.5,
#   ...
# }
```

#### 9.2. Load Baseline Team

**Baseline:** TÃ­nh tá»« cÃ¡c cuá»™c gá»i "Ä‘áº¡t chuáº©n" (QA score â‰¥8.0) cá»§a cÃ¹ng team

```python
def load_baseline(team_name, call_type):
    """
    Load baseline tá»« database
    
    Baseline Ä‘Æ°á»£c cáº­p nháº­t Ä‘á»‹nh ká»³ (tuáº§n/thÃ¡ng)
    """
    baseline = db.query("""
        SELECT 
            AVG(median_wpm) as base_wpm,
            STDDEV(median_wpm) as std_wpm,
            COUNT(*) as sample_count
        FROM call_metrics
        WHERE team = :team
          AND call_type = :call_type
          AND qa_score >= 8.0
          AND created_at >= NOW() - INTERVAL '90 days'
    """, team=team_name, call_type=call_type)
    
    return {
        "base_wpm": baseline["base_wpm"],
        "std_wpm": baseline["std_wpm"],
        "sample_count": baseline["sample_count"]
    }

# VÃ­ dá»¥
baseline = load_baseline("Sales_BH", "BH")
# Output: {
#   "base_wpm": 150.0,
#   "std_wpm": 20.0,
#   "sample_count": 245
# }
```

#### 9.3. TÃ­nh Outlier Ratio

**CÃ´ng thá»©c:**
```
r_out(Â±kÏƒ) = (sá»‘ segments ngoÃ i [base - kÃ—Ïƒ, base + kÃ—Ïƒ]) / tá»•ng segments

k=1 â†’ Â±1Ïƒ (68% trÆ°á»ng há»£p bÃ¬nh thÆ°á»ng)
k=2 â†’ Â±2Ïƒ (95%)
k=2.5 â†’ Â±2.5Ïƒ (99%)
```

**Process:**
```python
def calculate_outlier_ratio(wpm_results, baseline, k=1):
    """
    TÃ­nh tá»· lá»‡ segments vÆ°á»£t ngÆ°á»¡ng Â±kÃ—Ïƒ
    """
    base = baseline["base_wpm"]
    std = baseline["std_wpm"]
    
    lower_bound = base - k * std
    upper_bound = base + k * std
    
    wpm_values = [r["wpm"] for r in wpm_results]
    
    outliers = []
    for i, wpm in enumerate(wpm_values):
        if wpm < lower_bound or wpm > upper_bound:
            outliers.append({
                "segment_id": wpm_results[i]["segment_id"],
                "wpm": wpm,
                "deviation": wpm - base,
                "direction": "too_fast" if wpm > upper_bound else "too_slow"
            })
    
    outlier_ratio = len(outliers) / len(wpm_values)
    
    return {
        "k": k,
        "lower_bound": lower_bound,
        "upper_bound": upper_bound,
        "outlier_ratio": outlier_ratio,
        "outlier_count": len(outliers),
        "total_segments": len(wpm_values),
        "outliers": outliers
    }

# TÃ­nh cho nhiá»u k
outlier_1sigma = calculate_outlier_ratio(wpm_results, baseline, k=1)
outlier_2sigma = calculate_outlier_ratio(wpm_results, baseline, k=2)
outlier_2_5sigma = calculate_outlier_ratio(wpm_results, baseline, k=2.5)
```

**Output:**
```json
{
  "k": 1,
  "lower_bound": 130.0,  // base - 1Ã—std = 150 - 20
  "upper_bound": 170.0,  // base + 1Ã—std = 150 + 20
  "outlier_ratio": 0.28,  // 28% segments ngoÃ i khoáº£ng
  "outlier_count": 7,
  "total_segments": 25,
  "outliers": [
    {
      "segment_id": "S2",
      "wpm": 68.9,
      "deviation": -81.1,
      "direction": "too_slow"
    },
    {
      "segment_id": "S5",
      "wpm": 194.6,
      "deviation": 44.6,
      "direction": "too_fast"  â† VI PHáº M!
    },
    ...
  ]
}
```

**Thá»i gian:** 0.2 giÃ¢y

---

### BÆ°á»›c 10: PhÃ¡t hiá»‡n Customer Impact

**Má»¥c Ä‘Ã­ch:** PhÃ¡t hiá»‡n KH yÃªu cáº§u nháº¯c láº¡i hoáº·c than phiá»n vá» tá»‘c Ä‘á»™

**Process:**
```python
def detect_customer_impact(transcript_segments):
    """
    TÃ¬m cÃ¡c tÃ­n hiá»‡u KH phÃ n nÃ n vá» tá»‘c Ä‘á»™
    """
    # Patterns Ä‘á»ƒ detect
    patterns = {
        "request_repeat": [
            r"(nÃ³i láº¡i|nháº¯c láº¡i|láº·p láº¡i|nÃ³i tá»« tá»«|nÃ³i cháº­m)",
            r"(em Æ¡i|anh khÃ´ng nghe rÃµ|khÃ´ng hiá»ƒu)",
            r"(sao nÃ³i nhanh váº­y|nhanh quÃ¡)"
        ],
        "confusion": [
            r"(cÃ¡i gÃ¬|sao|háº£|gÃ¬ cÆ¡|khÃ´ng rÃµ)",
            r"(em nÃ³i rÃµ hÆ¡n|rÃµ rÃ ng hÆ¡n)"
        ]
    }
    
    customer_impacts = []
    customer_segments = [s for s in transcript_segments if s["speaker"] == "CUSTOMER"]
    
    for seg in customer_segments:
        text = seg["text"].lower()
        
        # Kiá»ƒm tra patterns
        for category, pattern_list in patterns.items():
            for pattern in pattern_list:
                if re.search(pattern, text):
                    customer_impacts.append({
                        "segment_id": seg["segment_id"],
                        "timestamp": seg["start"],
                        "text": seg["text"],
                        "category": category,
                        "pattern_matched": pattern
                    })
                    break
    
    return {
        "total_impacts": len(customer_impacts),
        "repeat_requests": len([c for c in customer_impacts if c["category"] == "request_repeat"]),
        "confusion_markers": len([c for c in customer_impacts if c["category"] == "confusion"]),
        "impacts": customer_impacts
    }

customer_impact = detect_customer_impact(transcript_segments)
```

**Output:**
```json
{
  "total_impacts": 3,
  "repeat_requests": 2,
  "confusion_markers": 1,
  "impacts": [
    {
      "segment_id": "C3",
      "timestamp": 55.2,
      "text": "Em Æ¡i, em nÃ³i cháº­m láº¡i Ä‘Æ°á»£c khÃ´ng?",
      "category": "request_repeat",
      "pattern_matched": "nÃ³i cháº­m"
    },
    {
      "segment_id": "C5",
      "timestamp": 67.8,
      "text": "Em láº·p láº¡i cÃ¡i Ä‘Ã³ Ä‘Æ°á»£c khÃ´ng anh khÃ´ng nghe rÃµ",
      "category": "request_repeat",
      "pattern_matched": "láº·p láº¡i"
    },
    {
      "segment_id": "C7",
      "timestamp": 82.5,
      "text": "CÃ¡i gÃ¬ cÆ¡ em?",
      "category": "confusion",
      "pattern_matched": "cÃ¡i gÃ¬"
    }
  ]
}
```

**Thá»i gian:** 0.2 giÃ¢y

---

### BÆ°á»›c 11: Context-Aware Gating

**Má»¥c Ä‘Ã­ch:** KhÃ´ng pháº¡t khi cÃ³ ngá»¯ cáº£nh há»£p lÃ½

**CÃ¡c trÆ°á»ng há»£p miá»…n trá»«:**

```python
def detect_context_flags(segment, next_customer_segment=None):
    """
    PhÃ¡t hiá»‡n cÃ¡c context cáº§n miá»…n trá»«
    """
    flags = {}
    text = segment["text"].lower()
    
    # 1. Äá»c OTP/MÃ£ xÃ¡c nháº­n
    if re.search(r'\b\d{4,6}\b', text) and \
       any(kw in text for kw in ["otp", "mÃ£ xÃ¡c nháº­n", "mÃ£ Ä‘Æ¡n"]):
        flags["reading_otp"] = True
    
    # 2. Äá»c Ä‘iá»u khoáº£n/ChÃ­nh sÃ¡ch
    if any(kw in text for kw in ["Ä‘iá»u khoáº£n", "quy Ä‘á»‹nh", "cam káº¿t", "chÃ­nh sÃ¡ch"]):
        if segment["word_count"] > 30:  # Äá»c dÃ i
            flags["reading_terms"] = True
    
    # 3. KH yÃªu cáº§u nÃ³i nhanh/cháº­m hÆ¡n
    if next_customer_segment:
        next_text = next_customer_segment["text"].lower()
        if any(phrase in next_text for phrase in 
               ["nÃ³i nhanh", "nhanh hÆ¡n", "cháº­m láº¡i", "tá»« tá»«"]):
            flags["customer_requests_pace"] = True
    
    # 4. Tra cá»©u/Kiá»ƒm tra há»‡ thá»‘ng
    if any(kw in text for kw in ["em kiá»ƒm tra", "cho em tra", "em xem giÃºp"]):
        flags["lookup_mode"] = True
    
    return flags

# Ãp dá»¥ng cho táº¥t cáº£ segments
for i, seg in enumerate(segments):
    next_cust_seg = get_next_customer_segment(segments, i)
    seg["context_flags"] = detect_context_flags(seg, next_cust_seg)
```

**Quy táº¯c Ã¡p dá»¥ng:**
```python
def apply_context_aware_gating(violation_level, context_flags, customer_impact_count):
    """
    Giáº£m hoáº·c miá»…n pháº¡t dá»±a trÃªn context
    
    NguyÃªn táº¯c:
    1. CÃ³ context há»£p lÃ½ â†’ háº¡ 1 má»©c hoáº·c miá»…n pháº¡t
    2. Æ¯u tiÃªn customer impact: náº¿u KH phÃ n nÃ n â†’ KHÃ”NG miá»…n pháº¡t
    """
    # Náº¿u cÃ³ customer impact cao â†’ Æ°u tiÃªn, khÃ´ng miá»…n
    if customer_impact_count >= 3:
        return violation_level  # KhÃ´ng giáº£m
    
    # CÃ³ context há»£p lÃ½ vÃ  impact tháº¥p â†’ giáº£m má»©c
    if any(context_flags.values()):
        if violation_level == "M1":
            return "OK"
        elif violation_level == "M2":
            return "M1"
        elif violation_level == "M3":
            return "M2"
    
    return violation_level
```

**Thá»i gian:** 0.1 giÃ¢y

---

### BÆ°á»›c 12: Mapping Má»©c Lá»—i M1/M2/M3

**Quy táº¯c mapping (Æ°u tiÃªn Customer Impact):**

```python
def map_violation_level(outlier_1sigma, outlier_2sigma, outlier_2_5sigma, 
                        customer_impact, context_flags):
    """
    Mapping má»©c lá»—i theo thá»© tá»± Æ°u tiÃªn:
    1. Customer Impact (cao nháº¥t)
    2. Outlier ratio + sigma levels
    3. Context-aware gating
    """
    violation_level = "OK"
    evidence = []
    
    # ==== NGÆ¯á» NG METRICS ====
    r_1sigma = outlier_1sigma["outlier_ratio"]
    r_2sigma = outlier_2sigma["outlier_ratio"]
    r_2_5sigma = outlier_2_5sigma["outlier_ratio"]
    
    # XÃ¡c Ä‘á»‹nh má»©c lá»—i ban Ä‘áº§u
    if r_2_5sigma >= 0.40:
        violation_level = "M3"
        evidence.append(f"r_out(Â±2.5Ïƒ) = {r_2_5sigma:.1%} â‰¥ 40%")
    elif r_2sigma >= 0.30:
        violation_level = "M2"
        evidence.append(f"r_out(Â±2Ïƒ) = {r_2sigma:.1%} â‰¥ 30%")
    elif r_1sigma >= 0.20:
        violation_level = "M1"
        evidence.append(f"r_out(Â±1Ïƒ) = {r_1sigma:.1%} â‰¥ 20%")
    
    # ==== CUSTOMER IMPACT (Æ°u tiÃªn cao nháº¥t) ====
    repeat_count = customer_impact["repeat_requests"]
    
    if repeat_count >= 3:
        # NÃ¢ng lÃªn Ã­t nháº¥t M2
        if violation_level in ["OK", "M1"]:
            violation_level = "M2"
        evidence.append(f"KH yÃªu cáº§u nháº¯c láº¡i {repeat_count} láº§n")
    
    # Kiá»ƒm tra hiá»ƒu sai ná»™i dung quan trá»ng
    if has_critical_misunderstanding(customer_impact):
        violation_level = "M3"
        evidence.append("GÃ¢y hiá»ƒu sai ná»™i dung quan trá»ng (OTP/Ä‘iá»u khoáº£n)")
    
    # ==== CONTEXT-AWARE GATING ====
    if any(context_flags.values()) and repeat_count < 3:
        violation_level = apply_context_aware_gating(
            violation_level, context_flags, repeat_count
        )
        evidence.append(f"Context: {', '.join([k for k, v in context_flags.items() if v])}")
    
    return {
        "violation_level": violation_level,
        "evidence": evidence,
        "metrics": {
            "r_out_1sigma": r_1sigma,
            "r_out_2sigma": r_2sigma,
            "r_out_2_5sigma": r_2_5sigma
        },
        "customer_impact_count": repeat_count,
        "context_flags": context_flags
    }
```

**Báº£ng mapping chi tiáº¿t:**

| Äiá»u kiá»‡n | Má»©c lá»—i | Evidence |
|-----------|---------|----------|
| r_out(Â±1Ïƒ) < 20% | **OK** | KhÃ´ng cÃ³ vi pháº¡m |
| r_out(Â±1Ïƒ) â‰¥ 20% | **M1** | Lá»‡ch nháº¹, KH váº«n theo ká»‹p |
| r_out(Â±2Ïƒ) â‰¥ 30% | **M2** | Lá»‡ch nhiá»u |
| KH yÃªu cáº§u nháº¯c láº¡i â‰¥3 láº§n | **M2** | Customer impact cao |
| r_out(Â±2.5Ïƒ) â‰¥ 40% | **M3** | Lá»‡ch ráº¥t nhiá»u |
| GÃ¢y hiá»ƒu sai OTP/Ä‘iá»u khoáº£n | **M3** | Critical misunderstanding |

**Output:**
```json
{
  "violation_level": "M2",
  "evidence": [
    "r_out(Â±2Ïƒ) = 32% â‰¥ 30%",
    "KH yÃªu cáº§u nháº¯c láº¡i 3 láº§n",
    "Outliers: S5 [50.0-65.3s] wpm=194.6 (quÃ¡ nhanh)"
  ],
  "metrics": {
    "r_out_1sigma": 0.28,
    "r_out_2sigma": 0.32,
    "r_out_2_5sigma": 0.12
  },
  "customer_impact_count": 3,
  "context_flags": {}
}
```

**Thá»i gian:** 0.1 giÃ¢y

---

### BÆ°á»›c 13: TÃ­nh Äiá»ƒm Trá»«

**Quy táº¯c trá»« Ä‘iá»ƒm:**

```python
def calculate_penalty(violation_level, call_type):
    """
    TÃ­nh Ä‘iá»ƒm trá»« theo má»©c lá»—i
    
    Quy táº¯c:
    - M1: Trá»« Ä‘Ãºng Ä‘iá»ƒm tiÃªu chÃ­ con
    - M2: Trá»« 50% Ä‘iá»ƒm NHÃ“M KNGT
    - M3: Äiá»ƒm NHÃ“M KNGT = 0
    """
    # Äiá»ƒm KNGT tá»‘i Ä‘a
    max_kngt = 2.0 if call_type == "BH" else 4.0
    
    # Äiá»ƒm tiÃªu chÃ­ con (A.2.1 Tá»‘c Ä‘á»™ nÃ³i = 1/3 cá»§a A.2)
    criterion_weight = 0.10  # 10% KNGT
    sub_criterion_weight = criterion_weight / 3  # 1/3 cá»§a 10%
    criterion_score = max_kngt * sub_criterion_weight
    
    if violation_level == "OK":
        penalty = 0.0
        final_score = max_kngt
    elif violation_level == "M1":
        penalty = criterion_score
        final_score = max_kngt - penalty
    elif violation_level == "M2":
        penalty = 0.5 * max_kngt  # Trá»« 50% nhÃ³m
        final_score = max_kngt - penalty
    elif violation_level == "M3":
        penalty = max_kngt  # NhÃ³m = 0
        final_score = 0.0
    
    return {
        "max_kngt": max_kngt,
        "criterion_score": criterion_score,
        "penalty": penalty,
        "final_kngt_score": final_score,
        "penalty_percentage": (penalty / max_kngt) * 100
    }

# VÃ­ dá»¥
penalty = calculate_penalty("M2", "BH")
```

**Output:**
```json
{
  "max_kngt": 2.0,
  "criterion_score": 0.067,  // 2.0 Ã— 10% Ã— 1/3
  "penalty": 1.0,  // 50% Ã— 2.0
  "final_kngt_score": 1.0,  // 2.0 - 1.0
  "penalty_percentage": 50.0
}
```

**Thá»i gian:** <0.1 giÃ¢y

---

### BÆ°á»›c 14: Sinh Evidence vÃ  BÃ¡o cÃ¡o

**Má»¥c Ä‘Ã­ch:** Táº¡o evidence chi tiáº¿t cho vi pháº¡m

```python
def generate_evidence(wpm_results, outlier_data, customer_impact, 
                      violation_level, baseline):
    """
    Sinh evidence vá»›i timestamps vÃ  trÃ­ch Ä‘oáº¡n transcript
    """
    evidence_items = []
    
    # 1. Outlier segments
    for outlier in outlier_data["outliers"]:
        seg_data = next(s for s in wpm_results if s["segment_id"] == outlier["segment_id"])
        
        evidence_items.append({
            "type": "metric_violation",
            "segment_id": outlier["segment_id"],
            "timestamp_start": seg_data["start"],
            "timestamp_end": seg_data["end"],
            "text_excerpt": seg_data["text_preview"],
            "metric": {
                "wpm": outlier["wpm"],
                "baseline": baseline["base_wpm"],
                "deviation": outlier["deviation"],
                "direction": outlier["direction"]
            }
        })
    
    # 2. Customer impact
    for impact in customer_impact["impacts"]:
        evidence_items.append({
            "type": "customer_impact",
            "timestamp": impact["timestamp"],
            "text_excerpt": impact["text"],
            "category": impact["category"]
        })
    
    # 3. Táº¡o summary
    summary = {
        "violation_level": violation_level,
        "total_segments": len(wpm_results),
        "outlier_count": outlier_data["outlier_count"],
        "customer_impact_count": customer_impact["total_impacts"],
        "baseline": f"{baseline['base_wpm']:.0f} Â± {baseline['std_wpm']:.0f} wpm",
        "agent_median": f"{np.median([r['wpm'] for r in wpm_results]):.0f} wpm"
    }
    
    return {
        "summary": summary,
        "evidence_items": evidence_items
    }
```

**Output:**
```json
{
  "summary": {
    "violation_level": "M2",
    "total_segments": 25,
    "outlier_count": 7,
    "customer_impact_count": 3,
    "baseline": "150 Â± 20 wpm",
    "agent_median": "148 wpm"
  },
  "evidence_items": [
    {
      "type": "metric_violation",
      "segment_id": "S5",
      "timestamp_start": 50.0,
      "timestamp_end": 65.3,
      "text_excerpt": "Anh quan tÃ¢m sáº£n pháº©m báº£o hiá»ƒm nhÃ¢n thá» khÃ´ng...",
      "metric": {
        "wpm": 194.6,
        "baseline": 150.0,
        "deviation": 44.6,
        "direction": "too_fast"
      }
    },
    {
      "type": "customer_impact",
      "timestamp": 67.8,
      "text_excerpt": "Em láº·p láº¡i cÃ¡i Ä‘Ã³ Ä‘Æ°á»£c khÃ´ng anh khÃ´ng nghe rÃµ",
      "category": "request_repeat"
    }
  ]
}
```

**Thá»i gian:** 0.2 giÃ¢y

---

## ğŸ“Š Tá»•ng há»£p Pipeline

### Timeline Äáº§y Ä‘á»§

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BÆ°á»›c 1: Chuáº©n bá»‹ Input (tá»©c thÃ¬)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BÆ°á»›c 2: STT (2-5s)                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BÆ°á»›c 3: Diarization (1-3s)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BÆ°á»›c 4: VAD (0.5-1s) â† NHANH!                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BÆ°á»›c 5: Chia Segments theo Speaker (0.1s)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BÆ°á»›c 6: Chia Segments DÃ i theo Pause (0.1s)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BÆ°á»›c 7: TÃ­nh Voiced Duration (0.1s)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BÆ°á»›c 8: TÃ­nh WPM cho tá»«ng Segment (0.2s)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BÆ°á»›c 9: Tá»•ng há»£p Metrics & So sÃ¡nh Baseline (0.2s)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BÆ°á»›c 10: PhÃ¡t hiá»‡n Customer Impact (0.2s)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BÆ°á»›c 11: Context-Aware Gating (0.1s)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BÆ°á»›c 12: Mapping Má»©c Lá»—i (0.1s)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BÆ°á»›c 13: TÃ­nh Äiá»ƒm Trá»« (0.1s)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BÆ°á»›c 14: Sinh Evidence & BÃ¡o cÃ¡o (0.2s)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Tá»”NG: ~5-10 giÃ¢y (cho cuá»™c gá»i 5 phÃºt)
      (60-80% lÃ  STT, khÃ´ng pháº£i Ä‘o tá»‘c Ä‘á»™!)
```

### Config Khuyáº¿n nghá»‹

```python
SPEECH_RATE_CONFIG = {
    # Segmentation
    "max_segment_duration": 15.0,      # seconds
    "min_segment_duration": 2.0,       # seconds
    "long_pause_threshold": 0.7,       # seconds (700ms)
    "overlap_tolerance": 0.2,          # seconds (200ms)
    
    # VAD
    "vad_frame_duration": 0.01,        # 10ms
    "vad_aggressiveness": 2,           # webrtcvad level (0-3)
    
    # Baseline
    "baseline_window_days": 90,        # 90 ngÃ y
    "baseline_min_qa_score": 8.0,      # Chá»‰ láº¥y cuá»™c gá»i Ä‘áº¡t â‰¥8.0
    "baseline_min_samples": 50,        # Tá»‘i thiá»ƒu 50 cuá»™c gá»i
    
    # Thresholds
    "min_voiced_duration": 1.0,        # Segment tá»‘i thiá»ƒu 1s
    "outlier_k_values": [1, 2, 2.5],   # TÃ­nh cho Â±1Ïƒ, Â±2Ïƒ, Â±2.5Ïƒ
    
    # Mapping thresholds
    "m1_threshold": 0.20,              # r_out(Â±1Ïƒ) â‰¥ 20%
    "m2_threshold": 0.30,              # r_out(Â±2Ïƒ) â‰¥ 30%
    "m3_threshold": 0.40,              # r_out(Â±2.5Ïƒ) â‰¥ 40%
    "m2_customer_impact_threshold": 3, # KH yÃªu cáº§u nháº¯c láº¡i â‰¥3 láº§n
    
    # Text splitting
    "text_split_method": "word_timestamps",  # Æ¯u tiÃªn
    "text_split_fallback": "duration_ratio"  # Fallback
}
```

---

## ğŸ“ VÃ­ dá»¥ Äáº§y Ä‘á»§ End-to-End

### Input
```
Audio: call_12345.wav (300 giÃ¢y = 5 phÃºt)
Agent: AGENT_001
Team: Sales_BH
Call Type: BH
```

### Output Cuá»‘i cÃ¹ng

```json
{
  "call_id": "12345",
  "agent_id": "AGENT_001",
  "team": "Sales_BH",
  "call_type": "BH",
  
  "criteria": {
    "name": "A.2.1 - Tá»‘c Ä‘á»™ nÃ³i",
    "group": "KNGT",
    "weight": 0.033,  // 10% Ã— 1/3
    "max_score": 0.067  // 2.0 Ã— 10% Ã— 1/3
  },
  
  "metrics": {
    "total_segments": 25,
    "agent_segments": 15,
    "median_wpm": 148.3,
    "p90_wpm": 192.1,
    "baseline": {
      "base_wpm": 150.0,
      "std_wpm": 20.0,
      "sample_count": 245
    },
    "outlier_ratio_1sigma": 0.28,
    "outlier_ratio_2sigma": 0.32,
    "outlier_ratio_2_5sigma": 0.12
  },
  
  "customer_impact": {
    "repeat_requests": 3,
    "confusion_markers": 1,
    "total_impacts": 4
  },
  
  "violation": {
    "level": "M2",
    "reason": [
      "r_out(Â±2Ïƒ) = 32% â‰¥ 30%",
      "KH yÃªu cáº§u nháº¯c láº¡i 3 láº§n"
    ]
  },
  
  "penalty": {
    "amount": 1.0,
    "percentage": 50.0,
    "description": "Trá»« 50% Ä‘iá»ƒm nhÃ³m KNGT"
  },
  
  "score": {
    "max_kngt": 2.0,
    "final_kngt": 1.0,
    "criterion_penalty": 0.067
  },
  
  "evidence": [
    {
      "type": "metric_violation",
      "segment_id": "S5",
      "timestamp": "[50.0 - 65.3s]",
      "text": "Anh quan tÃ¢m sáº£n pháº©m báº£o hiá»ƒm nhÃ¢n thá» khÃ´ng...",
      "wpm": 194.6,
      "deviation": "+44.6 wpm (quÃ¡ nhanh)"
    },
    {
      "type": "customer_impact",
      "timestamp": "67.8s",
      "text": "Em láº·p láº¡i cÃ¡i Ä‘Ã³ Ä‘Æ°á»£c khÃ´ng anh khÃ´ng nghe rÃµ",
      "category": "request_repeat"
    }
  ],
  
  "recommendations": [
    "Agent nÃªn giáº£m tá»‘c Ä‘á»™ nÃ³i xuá»‘ng, Ä‘áº·c biá»‡t táº¡i segment S5",
    "LÆ°u Ã½ pause sau cÃ¡c cÃ¢u quan trá»ng Ä‘á»ƒ KH cÃ³ thá»i gian xá»­ lÃ½",
    "Quan sÃ¡t pháº£n á»©ng KH, náº¿u KH yÃªu cáº§u nháº¯c láº¡i thÃ¬ Ä‘iá»u chá»‰nh ngay"
  ]
}
```

---

## âœ… Checklist Triá»ƒn khai

### Phase 1: MVP (Tuáº§n 1-2)
- [ ] TÃ­ch há»£p STT (Whisper hoáº·c Google Cloud STT)
- [ ] TÃ­ch há»£p Diarization (pyannote.audio)
- [ ] Implement VAD (webrtcvad)
- [ ] Implement segmentation cÆ¡ báº£n (speaker-based)
- [ ] TÃ­nh WPM theo cÃ´ng thá»©c Ä‘Æ¡n giáº£n
- [ ] Chia text theo tá»· lá»‡ thá»i gian (phÆ°Æ¡ng phÃ¡p 1)
- [ ] TÃ­nh outlier ratio vá»›i baseline cá»‘ Ä‘á»‹nh táº¡m

### Phase 2: Production (Tuáº§n 3-4)
- [ ] Thu tháº­p baseline tá»« dá»¯ liá»‡u thá»±c táº¿ (200-500 cuá»™c gá»i/team)
- [ ] Implement chia segment dÃ i theo pause
- [ ] TÃ­nh voiced_duration chÃ­nh xÃ¡c vá»›i VAD
- [ ] PhÃ¡t hiá»‡n customer impact vá»›i regex patterns
- [ ] Implement context-aware gating
- [ ] Mapping má»©c lá»—i M1/M2/M3 Ä‘áº§y Ä‘á»§
- [ ] Sinh evidence vá»›i timestamps

### Phase 3: Optimization (Tuáº§n 5+)
- [ ] Upgrade lÃªn word-level timestamps (phÆ°Æ¡ng phÃ¡p 2)
- [ ] Cáº­p nháº­t baseline tá»± Ä‘á»™ng (hÃ ng tuáº§n/thÃ¡ng)
- [ ] Monitor drift detection
- [ ] A/B test cÃ¡c threshold
- [ ] Fine-tune patterns cho customer impact
- [ ] Optimize performance (parallel processing, caching)

---

## ğŸ”§ Troubleshooting

### Váº¥n Ä‘á» thÆ°á»ng gáº·p

**1. VAD phÃ¡t hiá»‡n sai (nhiá»u false positive/negative)**
```
Giáº£i phÃ¡p:
- Äiá»u chá»‰nh aggressiveness level (0-3)
- Káº¿t há»£p vá»›i ASR confidence
- Filter cÃ¡c segment cÃ³ word_count=0
```

**2. Baseline khÃ´ng Ä‘áº¡i diá»‡n**
```
Giáº£i phÃ¡p:
- TÄƒng window_days lÃªn 120-180 ngÃ y
- Giáº£m min_qa_score xuá»‘ng 7.5
- TÃ¡ch baseline theo sáº£n pháº©m/campaign cá»¥ thá»ƒ
```

**3. QuÃ¡ nhiá»u false positive (pháº¡t oan)**
```
Giáº£i phÃ¡p:
- TÄƒng threshold (M1: 20% â†’ 25%)
- Kiá»ƒm tra customer impact ká»¹ hÆ¡n
- Má»Ÿ rá»™ng context-aware patterns
```

**4. KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c vi pháº¡m rÃµ rÃ ng**
```
Giáº£i phÃ¡p:
- Giáº£m threshold (M2: 30% â†’ 25%)
- TÄƒng trá»ng sá»‘ customer impact
- Review baseline cÃ³ Ä‘Ãºng khÃ´ng
```

---

## ğŸ“š Tham kháº£o

- [05_Scoring_Criteria_Decomposition.md](./05_Scoring_Criteria_Decomposition.md)
- [07_Segmentation_Strategy_Detailed.md](./07_Segmentation_Strategy_Detailed.md)
- [08_Pause_Based_Splitting_Visual_Guide.md](./08_Pause_Based_Splitting_Visual_Guide.md)
- [09_VAD_Latency_And_Text_Splitting.md](./09_VAD_Latency_And_Text_Splitting.md)
- [Master Spec](./00_Master_Spec.md)

---

**Káº¿t luáº­n:** Quy trÃ¬nh Ä‘Ã¡nh giÃ¡ tá»‘c Ä‘á»™ nÃ³i gá»“m 14 bÆ°á»›c, tá»« chuáº©n bá»‹ input Ä‘áº¿n sinh bÃ¡o cÃ¡o cuá»‘i cÃ¹ng. Tá»•ng thá»i gian ~5-10 giÃ¢y cho cuá»™c gá»i 5 phÃºt, trong Ä‘Ã³ STT chiáº¿m 60-80%. VAD vÃ  cÃ¡c bÆ°á»›c Ä‘o tá»‘c Ä‘á»™ **Ráº¤T NHANH, KHÃ”NG gÃ¢y trá»…**.