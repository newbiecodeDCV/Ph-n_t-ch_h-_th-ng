# THI·∫æT K·∫æ H·ªÜ TH·ªêNG - THEO CHU·∫®N CASE D·ª∞ √ÅN

**Version:** 2.0  
**Ng√†y:** 10/10/2025  
**T√°c gi·∫£:** System Design Team  
**Tu√¢n th·ªß:** Master Spec v0.1 + UC01 Re-Spec

---

## üìã M·ª§C L·ª§C

1. [T·ªïng quan 2 CASE](#1-t·ªïng-quan-2-case)
2. [CASE 2: Call Scoring & Coaching (∆Øu ti√™n)](#2-case-2-call-scoring--coaching)
3. [Ki·∫øn tr√∫c t·ªïng th·ªÉ CASE 2](#3-ki·∫øn-tr√∫c-t·ªïng-th·ªÉ-case-2)
4. [Components chi ti·∫øt](#4-components-chi-ti·∫øt)
5. [Data Flow & Sequence](#5-data-flow--sequence)
6. [Database Schema](#6-database-schema)
7. [API Design](#7-api-design)
8. [Call Type Detection (Audio-only)](#8-call-type-detection-audio-only)
9. [Speech Rate Evaluation (SR - KNGT)](#9-speech-rate-evaluation-sr---kngt)
10. [CASE 1: CRM Compliance (Tham chi·∫øu)](#10-case-1-crm-compliance)

---

## 1. T·ªîNG QUAN 2 CASE

### 1.1. CASE Definitions

#### **CASE 1 ‚Äì CRM Compliance**
- **M·ª•c ti√™u:** Ki·ªÉm tra Agent c√≥ c·∫≠p nh·∫≠t CRM/ticket ƒë√∫ng quy ƒë·ªãnh
- **Input:** CRM records (notes, ticket, opportunity, updated_at), call metadata
- **Output:** Violations (M1/M2/M3), Reminders, Reports
- **Ph·∫°m vi:** Ch·ªâ ƒë√°nh gi√° **NTT (Nh·∫≠p th√¥ng tin)** - 10% t·ªïng ƒëi·ªÉm
- **KPIs:** Detection rate, False positive <5%, Resolution rate >85%

#### **CASE 2 ‚Äì Call Scoring & Coaching** ‚≠ê (∆Øu ti√™n cao)
- **M·ª•c ti√™u:** Ch·∫•m ƒëi·ªÉm ch·∫•t l∆∞·ª£ng cu·ªôc g·ªçi theo **KNGT + KNBH**
- **Input:** Audio + Transcript (diarization) + Metadata
- **Output:** Score (0-10), Summary, Recommendations, Suggested Scripts, Evidence
- **Ph·∫°m vi:** KNGT (40-70%) + KNBH (30-60%) - T√πy call_type
- **KPIs:** MAE ‚â§1.0, F1 M2/M3 ‚â•0.8, Latency ‚â§5s (kh√¥ng t√≠nh STT)

### 1.2. Ph√¢n b·ªï ƒëi·ªÉm theo lo·∫°i cu·ªôc g·ªçi

| Nh√≥m | BH | CSKH | Ghi ch√∫ |
|------|-----|------|---------|
| **KNGT** (K·ªπ nƒÉng giao ti·∫øp) | 40% (4.0 ƒëi·ªÉm) | 70% (7.0 ƒëi·ªÉm) | CSKH c·∫ßn empathy cao h∆°n |
| **KNBH/KNSV** (K·ªπ nƒÉng b√°n h√†ng/d·ªãch v·ª•) | 60% (6.0 ƒëi·ªÉm) | 30% (3.0 ƒëi·ªÉm) | BH focus outcomes |
| **NTT** (Nh·∫≠p CRM) | 10% (1.0 ƒëi·ªÉm) | 10% (1.0 ƒëi·ªÉm) | X·ª≠ l√Ω ·ªü CASE 1 (UC09) |

**T·ªïng:** 110% ‚Üí UC01 ch·ªâ ch·∫•m KNGT+KNBH = 100%, NTT ri√™ng bi·ªát

### 1.3. Quy t·∫Øc tr·ª´ ƒëi·ªÉm

| M·ª©c ƒë·ªô | KNGT & KNBH | NTT (CASE 1) |
|--------|-------------|--------------|
| **OK** | Kh√¥ng tr·ª´ ƒëi·ªÉm | Kh√¥ng tr·ª´ |
| **M1** | Tr·ª´ ƒëi·ªÉm ti√™u ch√≠ con (theo tr·ªçng s·ªë) | Tr·ª´ 20% |
| **M2** | Tr·ª´ 50% ƒëi·ªÉm nh√≥m | Tr·ª´ 50% |
| **M3** | ƒêi·ªÉm nh√≥m = 0 | ƒêi·ªÉm nh√≥m = 0 |

---

## 2. CASE 2: CALL SCORING & COACHING

### 2.1. Actors

| Actor | Vai tr√≤ | T∆∞∆°ng t√°c |
|-------|---------|-----------|
| **Agent (Sales/CSKH)** | Ng∆∞·ªùi th·ª±c hi·ªán cu·ªôc g·ªçi | Nh·∫≠n k·∫øt qu·∫£, xem evidence, recommendations |
| **QA Reviewer** | Ki·ªÉm ƒë·ªãnh ch·∫•t l∆∞·ª£ng | Review k·∫øt qu·∫£, ƒëi·ªÅu ch·ªânh thresholds |
| **Team Manager** | Qu·∫£n l√Ω ƒë·ªôi | Xem b√°o c√°o t·ªïng h·ª£p, xu h∆∞·ªõng |
| **System Admin** | V·∫≠n h√†nh h·ªá th·ªëng | Config rules, monitor performance |
| **PBX/Telephony** | H·ªá th·ªëng g·ªçi | G·ª≠i audio + metadata |

### 2.2. Use Case Flow (High-level)

```mermaid
flowchart TB
    A[PBX g·ª≠i Audio + Metadata] --> B[STT + Diarization]
    B --> C[Call Type Detection<br/>audio-only]
    B --> D[Feature Extraction<br/>wpm, pause, interrupts]
    
    C --> E{Confidence >= œÑ?}
    E -->|Yes| F[Apply Weight theo Type]
    E -->|No| G[Mixture-of-Weights]
    
    D --> H[Evaluate KNGT]
    D --> I[Evaluate KNBH]
    
    F --> H
    F --> I
    G --> H
    G --> I
    
    H --> J[Calculate Total Score]
    I --> J
    
    J --> K[Generate Summary]
    J --> L[Generate Recommendations]
    J --> M[Map Suggested Scripts]
    
    K --> N[Save to DB + Cache]
    L --> N
    M --> N
    
    N --> O[Return Report to UI]
```

### 2.3. Input Specification

#### B·∫Øt bu·ªôc:
```json
{
  "call_id": "CALL-2025-001",
  "agent_id": "AG001",
  "call_time": "2025-10-10T10:30:00Z",
  "audio_url": "s3://calls/CALL-2025-001.wav",
  "transcript": [
    {
      "speaker": "AGENT",
      "start": 0.0,
      "end": 5.2,
      "text": "Ch√†o anh, em l√† t∆∞ v·∫•n vi√™n c·ªßa..."
    },
    {
      "speaker": "CUSTOMER",
      "start": 5.5,
      "end": 8.0,
      "text": "V√¢ng, em nghe"
    }
  ]
}
```

#### Kh√¥ng y√™u c·∫ßu:
- ‚ùå `call_type` (h·ªá th·ªëng t·ª± ph√°t hi·ªán t·ª´ audio)
- ‚ùå `crm_data` (ch·ªâ c·∫ßn cho NTT/CASE 1)

#### Features t·ªëi thi·ªÉu (ƒë∆∞·ª£c extract t·ª± ƒë·ªông):
- `wpm` (words per minute) theo segment
- `pause_ratio` (% th·ªùi gian im l·∫∑ng)
- `interrupt_count` (s·ªë l·∫ßn ng·∫Øt l·ªùi)
- `sentiment_trend` (xu h∆∞·ªõng c·∫£m x√∫c)
- `customer_repeat_count` (KH y√™u c·∫ßu nh·∫Øc l·∫°i)
- `explicit_complaint` flags (ph√†n n√†n r√µ r√†ng)

### 2.4. Output Specification

```json
{
  "call_id": "CALL-2025-001",
  "agent_id": "AG001",
  "call_time": "2025-10-10T10:30:00Z",
  
  "call_type_detection": {
    "predicted": "BH",
    "confidence": 0.85,
    "method": "audio_only",
    "signals": {
      "keywords": ["g√≥i b·∫£o hi·ªÉm", "∆∞u ƒë√£i", "ph√≠"],
      "interaction_pattern": "agent_led_sales",
      "first_60s_sentiment": "neutral_to_positive"
    }
  },
  
  "score": {
    "total": 7.8,
    "label": "Kh√°",
    "passed": true,
    "weights_used": {
      "KNGT": 0.4,
      "KNBH": 0.6
    },
    "groups": {
      "KNGT": {
        "points": 3.1,
        "max_points": 4.0,
        "percentage": 77.5,
        "criteria": [
          {
            "code": "GRT",
            "name": "Ch√†o h·ªèi & x∆∞ng danh",
            "weight": 0.05,
            "max_points": 0.2,
            "earned_points": 0.2,
            "violation_level": "OK"
          },
          {
            "code": "SR",
            "name": "T·ªëc ƒë·ªô n√≥i & r√µ r√†ng",
            "weight": 0.08,
            "max_points": 0.32,
            "earned_points": 0.24,
            "violation_level": "M1",
            "evidence": {
              "median_wpm": 185,
              "baseline_wpm": 155,
              "segments_violated": 3,
              "total_segments": 18,
              "customer_impact": 0,
              "timestamps": ["00:04:10-00:04:35", "00:07:20-00:07:50"]
            }
          }
        ]
      },
      "KNBH": {
        "points": 4.7,
        "max_points": 6.0,
        "percentage": 78.3,
        "criteria": [
          {
            "code": "NEED",
            "name": "Khai th√°c nhu c·∫ßu",
            "weight": 0.10,
            "max_points": 0.6,
            "earned_points": 0.3,
            "violation_level": "M2",
            "evidence": {
              "open_questions": 1,
              "expected_min": 2,
              "quote": "Anh c√≥ quan t√¢m ƒë·∫øn b·∫£o hi·ªÉm kh√¥ng ·∫°?",
              "timestamps": ["00:02:10-00:02:30"],
              "reason": "C√¢u h·ªèi ƒë√≥ng, ch∆∞a l√†m r√µ nhu c·∫ßu c·ªët l√µi"
            }
          }
        ]
      }
    }
  },
  
  "summary": {
    "text": "Cu·ªôc g·ªçi BH v·ªÅ g√≥i b·∫£o hi·ªÉm s·ª©c kh·ªèe. KH quan t√¢m ƒë·∫øn quy·ªÅn l·ª£i v√† chi ph√≠. Agent ƒë√£ gi·ªõi thi·ªáu 2 g√≥i ph√π h·ª£p, gi·∫£i th√≠ch ƒëi·ªÅu kho·∫£n v√† ∆∞u ƒë√£i. K·∫øt qu·∫£: KH ƒë·ªìng √Ω nh·∫≠n b√°o gi√° chi ti·∫øt qua email. Next step: G·ª≠i proposal trong 24h.",
    "highlights": [
      "Agent ch√†o h·ªèi chuy√™n nghi·ªáp, x∆∞ng danh r√µ r√†ng",
      "T·ªëc ƒë·ªô n√≥i h∆°i nhanh khi tr√¨nh b√†y ƒëi·ªÅu kho·∫£n (185 wpm)",
      "Ch∆∞a khai th√°c ƒë·ªß nhu c·∫ßu c·ªët l√µi c·ªßa KH",
      "Gi·∫£i th√≠ch s·∫£n ph·∫©m r√µ r√†ng, so s√°nh 2 g√≥i hi·ªáu qu·∫£",
      "Ch·ªët CTA r√µ r√†ng, x√°c nh·∫≠n next step"
    ]
  },
  
  "recommendations": [
    {
      "priority": "high",
      "category": "KNGT",
      "criterion": "SR",
      "message": "Gi·∫£m t·ªëc ƒë·ªô xu·ªëng 130-140 wpm khi tr√¨nh b√†y ƒëi·ªÅu kho·∫£n quan tr·ªçng. Xen k·∫Ω c√¢u ng·∫Øn v√† ki·ªÉm tra s·ª± hi·ªÉu c·ªßa KH b·∫±ng c√¢u h·ªèi: 'Anh c√≥ th·∫Øc m·∫Øc ƒëi·ªÉm n√†o kh√¥ng ·∫°?'",
      "actionable": true
    },
    {
      "priority": "high",
      "category": "KNBH",
      "criterion": "NEED",
      "message": "D√πng 2-3 c√¢u h·ªèi m·ªü ƒë·ªÉ l√†m r√µ nhu c·∫ßu c·ªët l√µi tr∆∞·ªõc khi t∆∞ v·∫•n. V√≠ d·ª•: 'Anh/ch·ªã quan t√¢m ƒë·∫øn b·∫£o hi·ªÉm v√¨ l√Ω do g√¨ ·∫°?', 'Hi·ªán t·∫°i anh/ch·ªã c√≥ b·∫£o hi·ªÉm n√†o ch∆∞a ·∫°?'",
      "actionable": true
    }
  ],
  
  "suggested_scripts": [
    {
      "id": "scripts/bh/need_exploration_v1",
      "stage": "need_identification",
      "text": "Em xin ph√©p h·ªèi th√™m ƒë·ªÉ t∆∞ v·∫•n ch√≠nh x√°c: Hi·ªán t·∫°i anh/ch·ªã ƒëang quan t√¢m ƒë·∫øn b·∫£o hi·ªÉm v√¨ l√Ω do g√¨ ·∫°? Anh/ch·ªã k·ª≥ v·ªçng quy·ªÅn l·ª£i n√†o l√† quan tr·ªçng nh·∫•t?",
      "when_to_use": "Khi c·∫ßn khai th√°c nhu c·∫ßu s√¢u h∆°n"
    },
    {
      "id": "scripts/bh/pace_control_v1",
      "stage": "product_explanation",
      "text": "Em xin gi·∫£i th√≠ch t·ª´ng ph·∫ßn ƒë·ªÉ anh/ch·ªã d·ªÖ theo d√µi. [Gi·∫£i th√≠ch ƒëi·ªÅu kho·∫£n 1]. Anh/ch·ªã c√≥ th·∫Øc m·∫Øc ƒëi·ªÉm n√†y kh√¥ng ·∫°? [ƒê·ª£i ph·∫£n h·ªìi]. Ti·∫øp theo l√†...",
      "when_to_use": "Khi tr√¨nh b√†y th√¥ng tin ph·ª©c t·∫°p"
    }
  ],
  
  "evidence": [
    {
      "type": "metric_violation",
      "criterion": "SR",
      "segment_id": "S5",
      "timestamp_start": 250.0,
      "timestamp_end": 275.0,
      "text": "Anh quan t√¢m g√≥i b·∫£o hi·ªÉm n√†y c√≥ quy·ªÅn l·ª£i n·∫±m vi·ªán t·ªëi ƒëa 365 ng√†y ph√≠ ph·∫´u thu·∫≠t chi tr·∫£ 100% kh√¥ng gi·ªõi h·∫°n...",
      "wpm": 205,
      "threshold": "fast (180-220)",
      "severity": "medium",
      "customer_impact": false
    },
    {
      "type": "criterion_violation",
      "criterion": "NEED",
      "timestamp_start": 130.0,
      "timestamp_end": 150.0,
      "text": "Anh c√≥ quan t√¢m ƒë·∫øn b·∫£o hi·ªÉm kh√¥ng ·∫°?",
      "reason": "C√¢u h·ªèi ƒë√≥ng (yes/no), kh√¥ng khai th√°c nhu c·∫ßu s√¢u",
      "severity": "high",
      "expected_behavior": "D√πng c√¢u h·ªèi m·ªü: 'Anh quan t√¢m ƒë·∫øn lo·∫°i b·∫£o hi·ªÉm n√†o ·∫°?' ho·∫∑c 'Anh ƒëang t√¨m b·∫£o hi·ªÉm ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ g√¨ ·∫°?'"
    }
  ],
  
  "metadata": {
    "processing_time_ms": 4500,
    "stt_duration_ms": 8000,
    "evaluation_method": "absolute_threshold",
    "baseline_available": false,
    "context_aware_rules_applied": ["pause_for_lookup", "reading_terms"],
    "created_at": "2025-10-10T10:35:25Z"
  }
}
```

---

## 3. KI·∫æN TR√öC T·ªîNG TH·ªÇ CASE 2

### 3.1. High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       CLIENT LAYER                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ PBX/Telephony‚îÇ  ‚îÇ  Agent UI    ‚îÇ  ‚îÇ QA Dashboard ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ   System     ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                  ‚îÇ                  ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   API Gateway   ‚îÇ
                    ‚îÇ  (Kong/Nginx)   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    APPLICATION LAYER                              ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ            Call Scoring & Coaching Service                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           CASE 2: Call Scoring Pipeline              ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇIngestion ‚îÇ‚Üí ‚îÇ   STT    ‚îÇ‚Üí ‚îÇCall Type ‚îÇ          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ Service  ‚îÇ  ‚îÇ+Diarize  ‚îÇ  ‚îÇDetector  ‚îÇ          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                                    ‚îÇ                 ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ Feature  ‚îÇ  ‚îÇ  KNGT    ‚îÇ  ‚îÇ  KNBH    ‚îÇ          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇExtractor ‚îÇ‚Üí ‚îÇEvaluator ‚îÇ  ‚îÇEvaluator ‚îÇ          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                     ‚îÇ              ‚îÇ                 ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ Summary  ‚îÇ  ‚îÇ   Score Calculator   ‚îÇ            ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇGenerator ‚îÇ  ‚îÇ  (Weight Applier)    ‚îÇ            ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ       ‚îÇ                   ‚îÇ                          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇRecomm-   ‚îÇ  ‚îÇScript Mapper   ‚îÇ                  ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇendation  ‚îÇ  ‚îÇ                ‚îÇ                  ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                  ‚îÇ                                   ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ         ‚îÇEvidence Generator‚îÇ                         ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                     ‚îÇ                                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           CASE 1: CRM Compliance (UC09)            ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  (T√°ch bi·ªát, ch·ªâ ƒë√°nh gi√° NTT - 10% ƒëi·ªÉm)          ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        DATA LAYER                                 ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ  PostgreSQL  ‚îÇ  ‚îÇ    Redis     ‚îÇ  ‚îÇ      S3      ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ   (Scores)   ‚îÇ  ‚îÇ   (Cache)    ‚îÇ  ‚îÇ   (Audio)    ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇElasticsearch ‚îÇ  ‚îÇ   RabbitMQ   ‚îÇ  ‚îÇ  Prometheus  ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  (Logging)   ‚îÇ  ‚îÇ   (Queue)    ‚îÇ  ‚îÇ  (Metrics)   ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3.2. Component Responsibilities (CASE 2)

| Component | Tr√°ch nhi·ªám | Input | Output | Technology |
|-----------|-------------|-------|--------|------------|
| **Ingestion Service** | Nh·∫≠n audio + metadata, validate | Call data + audio URL | Job ID queued | FastAPI |
| **STT + Diarization** | Speech-to-text + ph√¢n ng∆∞·ªùi n√≥i | Audio file | Transcript + segments | Whisper/Google STT |
| **Call Type Detector** | Ph√°t hi·ªán BH/CSKH t·ª´ audio | Transcript (60s ƒë·∫ßu) | call_type + confidence | Python + ML |
| **Feature Extractor** | Tr√≠ch xu·∫•t signals | Transcript + audio | wpm, pause_ratio, interrupts... | Python + VAD |
| **KNGT Evaluator** | ƒê√°nh gi√° k·ªπ nƒÉng giao ti·∫øp | Features + transcript | Violations + scores | Python + Rules |
| **KNBH Evaluator** | ƒê√°nh gi√° k·ªπ nƒÉng b√°n h√†ng/d·ªãch v·ª• | Features + transcript | Violations + scores | Python + Rules |
| **Score Calculator** | T√≠nh ƒëi·ªÉm t·ªïng theo weights | Violations + call_type | Total score + breakdown | Python |
| **Summary Generator** | T·∫°o t√≥m t·∫Øt 3-5 c√¢u | Transcript + scores | Executive summary | Python + LLM |
| **Recommendation** | G·ª£i √Ω c·∫£i thi·ªán | Violations | Actionable recommendations | Python + Templates |
| **Script Mapper** | Map k·ªãch b·∫£n m·∫´u | Violations + call_type | Script IDs | Python + DB |
| **Evidence Generator** | T·∫°o b·∫±ng ch·ª©ng | Violations + segments | Evidence v·ªõi timestamps | Python |

---

## 4. COMPONENTS CHI TI·∫æT

### 4.1. Call Type Detector (Audio-only)

**M·ª•c ti√™u:** Ph√°t hi·ªán lo·∫°i cu·ªôc g·ªçi (BH/CSKH) t·ª´ audio/transcript, KH√îNG d·ª±a v√†o CRM

**Input:**
```python
{
    "transcript": [...],  # ∆Øu ti√™n 30-60s ƒë·∫ßu
    "call_metadata": {
        "duration": 300.5,
        "agent_id": "AG001"
    }
}
```

**Signals:**

1. **T·ª´ kh√≥a/Ch·ªß ƒë·ªÅ:**
   - BH: "g√≥i b·∫£o hi·ªÉm", "∆∞u ƒë√£i", "ph√≠", "quy·ªÅn l·ª£i", "gi√°", "khuy·∫øn m√£i"
   - CSKH: "l·ªói", "kh√¥ng ho·∫°t ƒë·ªông", "khi·∫øu n·∫°i", "h·ªó tr·ª£", "b√°o l·ªói", "fix"

2. **H√†nh ƒë·ªông h·ªôi tho·∫°i:**
   - BH: Gi·ªõi thi·ªáu s·∫£n ph·∫©m, h·ªèi nhu c·∫ßu, so s√°nh g√≥i
   - CSKH: X√°c minh v·∫•n ƒë·ªÅ, h∆∞·ªõng d·∫´n kh·∫Øc ph·ª•c, t·∫°o ticket

3. **M·∫´u t∆∞∆°ng t√°c ƒë·∫ßu cu·ªôc g·ªçi:**
   - BH: Agent ch·ªß ƒë·ªông ch√†o h·ªèi, d·∫´n d·∫Øt
   - CSKH: Kh√°ch h√†ng m·ªü ƒë·∫ßu v·ªõi v·∫•n ƒë·ªÅ

4. **Sentiment pattern:**
   - BH: neutral ‚Üí positive (thuy·∫øt ph·ª•c)
   - CSKH: negative/frustrated ‚Üí neutral/resolved

**Logic:**

```python
def detect_call_type(transcript: List[Dict]) -> Dict:
    """
    Detect call type from audio/transcript
    
    Returns:
        {
            "predicted": "BH" | "CSKH",
            "confidence": float [0-1],
            "signals": {...}
        }
    """
    # L·∫•y 60s ƒë·∫ßu
    first_60s = [seg for seg in transcript if seg["end"] <= 60]
    
    # 1. Keywords scoring
    bh_keywords = ["g√≥i", "b·∫£o hi·ªÉm", "∆∞u ƒë√£i", "ph√≠", "quy·ªÅn l·ª£i", "gi√°"]
    cskh_keywords = ["l·ªói", "kh√¥ng ho·∫°t ƒë·ªông", "khi·∫øu n·∫°i", "h·ªó tr·ª£", "fix"]
    
    bh_score = count_keywords(first_60s, bh_keywords)
    cskh_score = count_keywords(first_60s, cskh_keywords)
    
    # 2. Interaction pattern
    first_speaker = transcript[0]["speaker"]
    if first_speaker == "AGENT":
        pattern_score_bh = 0.3
    else:
        pattern_score_bh = -0.2
    
    # 3. Sentiment trend
    sentiment_trend = analyze_sentiment_trend(first_60s)
    if sentiment_trend == "neutral_to_positive":
        sentiment_score_bh = 0.2
    elif sentiment_trend == "negative_to_neutral":
        sentiment_score_bh = -0.3
    else:
        sentiment_score_bh = 0
    
    # 4. Calculate confidence
    total_score_bh = bh_score + pattern_score_bh + sentiment_score_bh
    total_score_cskh = cskh_score - pattern_score_bh - sentiment_score_bh
    
    # Normalize to probability
    exp_bh = np.exp(total_score_bh)
    exp_cskh = np.exp(total_score_cskh)
    prob_bh = exp_bh / (exp_bh + exp_cskh)
    
    predicted = "BH" if prob_bh > 0.5 else "CSKH"
    confidence = max(prob_bh, 1 - prob_bh)
    
    return {
        "predicted": predicted,
        "confidence": confidence,
        "signals": {
            "bh_keyword_count": bh_score,
            "cskh_keyword_count": cskh_score,
            "first_speaker": first_speaker,
            "sentiment_trend": sentiment_trend,
            "prob_bh": prob_bh
        }
    }
```

**√Åp d·ª•ng weights:**

```python
TAU = 0.75  # Ng∆∞·ª°ng confidence

def apply_weights(call_type_detection: Dict) -> Dict:
    """
    Apply weights based on call type confidence
    """
    predicted = call_type_detection["predicted"]
    confidence = call_type_detection["confidence"]
    
    if confidence >= TAU:
        # High confidence ‚Üí D√πng weight thu·∫ßn
        if predicted == "BH":
            return {"KNGT": 0.4, "KNBH": 0.6}
        else:
            return {"KNGT": 0.7, "KNBH": 0.3}
    else:
        # Low confidence ‚Üí Mixture-of-weights
        prob_bh = call_type_detection["signals"]["prob_bh"]
        prob_cskh = 1 - prob_bh
        
        weight_kngt = prob_bh * 0.4 + prob_cskh * 0.7
        weight_knbh = prob_bh * 0.6 + prob_cskh * 0.3
        
        return {
            "KNGT": weight_kngt,
            "KNBH": weight_knbh,
            "note": f"Mixture-of-weights applied (confidence={confidence:.2f})"
        }
```

---

### 4.2. KNGT Evaluator (K·ªπ nƒÉng giao ti·∫øp)

**7 Ti√™u ch√≠ KNGT:**

| Code | Ti√™u ch√≠ | BH Weight | CSKH Weight | T√≠n hi·ªáu ch√≠nh |
|------|----------|-----------|-------------|----------------|
| **GRT** | Ch√†o h·ªèi & x∆∞ng danh | 0.05 | 0.08 | Pattern matching ƒë·∫ßu cu·ªôc g·ªçi |
| **SR** | T·ªëc ƒë·ªô n√≥i & r√µ r√†ng | 0.08 | 0.10 | WPM + customer_repeat_count |
| **VOL** | √Çm l∆∞·ª£ng & nh·ªãp | 0.04 | 0.06 | Audio amplitude + pause_ratio |
| **LSN** | L·∫Øng nghe, kh√¥ng ng·∫Øt l·ªùi | 0.06 | 0.08 | interrupt_count + turn-taking |
| **EMP** | ƒê·ªìng c·∫£m & th√°i ƒë·ªô | 0.05 | 0.08 | Sentiment + t·ª´ ng·ªØ ƒë·ªìng c·∫£m |
| **LAN** | Ng√¥n ng·ªØ ph√π h·ª£p | 0.05 | 0.05 | Negative words + formality |
| **CLS** | K·∫øt th√∫c l·ªãch s·ª± | 0.07 | 0.07 | Pattern cu·ªëi cu·ªôc g·ªçi |

**Implementation:**

```python
class KNGTEvaluator:
    """
    Evaluate KNGT criteria
    """
    
    def evaluate(self, features: Dict, transcript: List[Dict]) -> Dict:
        """
        Main evaluation function
        """
        violations = []
        
        # 1. GRT - Ch√†o h·ªèi & x∆∞ng danh
        grt_violation = self.evaluate_grt(transcript)
        if grt_violation:
            violations.append(grt_violation)
        
        # 2. SR - T·ªëc ƒë·ªô n√≥i (QUAN TR·ªåNG - nh∆∞ ƒë√£ thi·∫øt k·∫ø)
        sr_violation = self.evaluate_sr(features["speech_rate"])
        if sr_violation:
            violations.append(sr_violation)
        
        # 3. VOL - √Çm l∆∞·ª£ng
        vol_violation = self.evaluate_vol(features["volume"])
        if vol_violation:
            violations.append(vol_violation)
        
        # 4. LSN - L·∫Øng nghe
        lsn_violation = self.evaluate_lsn(features["interrupts"])
        if lsn_violation:
            violations.append(lsn_violation)
        
        # 5. EMP - ƒê·ªìng c·∫£m
        emp_violation = self.evaluate_emp(transcript, features["sentiment"])
        if emp_violation:
            violations.append(emp_violation)
        
        # 6. LAN - Ng√¥n ng·ªØ
        lan_violation = self.evaluate_lan(transcript)
        if lan_violation:
            violations.append(lan_violation)
        
        # 7. CLS - K·∫øt th√∫c
        cls_violation = self.evaluate_cls(transcript)
        if cls_violation:
            violations.append(cls_violation)
        
        return {
            "violations": violations,
            "criteria_count": 7,
            "violated_count": len(violations)
        }
    
    def evaluate_sr(self, speech_rate_data: Dict) -> Optional[Dict]:
        """
        Evaluate Speech Rate - T·ªëc ƒë·ªô n√≥i
        
        S·ª≠ d·ª•ng logic ƒë√£ thi·∫øt k·∫ø trong c√°c file tr∆∞·ªõc:
        - Segmentation theo speaker + pause
        - WPM calculation
        - Customer Impact ∆∞u ti√™n cao
        - Absolute threshold (kh√¥ng d√πng baseline)
        """
        from speech_rate_evaluation import evaluate_speech_rate_no_baseline
        
        result = evaluate_speech_rate_no_baseline(
            segments=speech_rate_data["segments"],
            call_type=speech_rate_data["call_type"],
            transcript_segments=speech_rate_data["transcript"]
        )
        
        if result["violation"]["violation_level"] == "OK":
            return None
        
        return {
            "code": "SR",
            "name": "T·ªëc ƒë·ªô n√≥i & r√µ r√†ng",
            "level": result["violation"]["violation_level"],
            "evidence": result["evidence"],
            "metrics": result["metrics"]
        }
```

---

### 4.3. KNBH Evaluator (BH) vs KNSV Evaluator (CSKH)

**KNBH (B√°n h√†ng) - 7 ti√™u ch√≠:**

| Code | Ti√™u ch√≠ | Weight | T√≠n hi·ªáu |
|------|----------|--------|----------|
| **CIN** | X√°c nh·∫≠n th√¥ng tin | 0.05 | Pattern x√°c nh·∫≠n |
| **LEAD** | D·∫´n d·∫Øt cu·ªôc g·ªçi | 0.08 | Turn control |
| **NEED** | Khai th√°c nhu c·∫ßu | 0.10 | Open questions |
| **PRB** | N·∫Øm b·∫Øt v·∫•n ƒë·ªÅ | 0.07 | Problem identification |
| **ADV** | T∆∞ v·∫•n s·∫£n ph·∫©m | 0.10 | Product mention quality |
| **OBJ** | X·ª≠ l√Ω t·ª´ ch·ªëi | 0.07 | Objection handling |
| **CLS2** | Ch·ªët & CTA | 0.08 | Clear next steps |

**KNSV (CSKH) - 4 ti√™u ch√≠:**

| Code | Ti√™u ch√≠ | Weight | T√≠n hi·ªáu |
|------|----------|--------|----------|
| **ISS** | X√°c nh·∫≠n v·∫•n ƒë·ªÅ | 0.10 | Problem verification |
| **DGN** | Chu·∫©n ƒëo√°n nguy√™n nh√¢n | 0.08 | Root cause analysis |
| **SOL** | ƒê∆∞a gi·∫£i ph√°p & h∆∞·ªõng d·∫´n | 0.08 | Solution clarity |
| **FUP** | X√°c nh·∫≠n & follow-up | 0.04 | Follow-up commitment |

---

## 5. DATA FLOW & SEQUENCE

### 5.1. Sequence Diagram (Tu√¢n th·ªß UC01)

```mermaid
sequenceDiagram
    autonumber
    participant PBX as PBX/Telephony
    participant API as QA Scoring API
    participant STT as Speech-to-Text
    participant CTD as Call Type Detector
    participant FX as Feature Extractor
    participant KNGT as KNGT Evaluator
    participant KNBH as KNBH Evaluator
    participant SC as Score Calculator
    participant SUM as Summary Generator
    participant REC as Recommender
    participant SCR as Script Mapper
    participant EVD as Evidence Generator
    participant DB as Database
    participant UI as Agent/QA UI
    
    PBX->>API: POST /score (audio_url, metadata)
    API->>STT: Send audio for transcription
    STT-->>API: Transcript + diarization (AGENT/CUSTOMER)
    
    API->>CTD: Detect call type (audio-only, 60s ƒë·∫ßu)
    CTD-->>API: call_type_pred + confidence + signals
    
    API->>FX: Extract features (wpm, pause, interrupts...)
    FX-->>API: Features per segment
    
    par Evaluate KNGT
        API->>KNGT: Evaluate 7 criteria (SR, GRT, VOL...)
        KNGT-->>API: KNGT violations + scores
    and Evaluate KNBH/KNSV
        API->>KNBH: Evaluate criteria (NEED, ADV, CTA...)
        KNBH-->>API: KNBH violations + scores
    end
    
    API->>SC: Calculate total score (apply weights)
    SC-->>API: Total score + breakdown
    
    API->>SUM: Generate executive summary (3-5 sentences)
    SUM-->>API: Summary text + highlights
    
    API->>REC: Build recommendations (per violations)
    REC-->>API: Recommendations[]
    
    API->>SCR: Map suggested scripts
    SCR-->>API: ScriptIDs[]
    
    API->>EVD: Generate evidence (timestamps + quotes)
    EVD-->>API: Evidence[]
    
    API->>DB: Persist (score, summary, evidence, recs)
    DB-->>API: Ack with score_id
    
    API-->>UI: Return full report
```

### 5.2. Processing Pipeline (Celery)

```python
@app.task
def score_call_pipeline(job_id: str, call_data: Dict):
    """
    Main pipeline for CASE 2: Call Scoring
    
    Steps match UC01 sequence diagram
    """
    try:
        # Step 1: Download audio
        audio_path = download_audio(call_data["audio_url"])
        
        # Step 2: STT + Diarization
        transcript = stt_service.transcribe(audio_path, diarize=True)
        
        # Step 3: Call Type Detection (audio-only)
        call_type_detection = detect_call_type(transcript)
        
        # Step 4: Feature Extraction
        features = extract_features(audio_path, transcript)
        
        # Step 5: Apply Weights (based on confidence)
        weights = apply_weights(call_type_detection)
        
        # Step 6: Evaluate KNGT
        kngt_result = KNGTEvaluator().evaluate(features, transcript)
        
        # Step 7: Evaluate KNBH/KNSV
        if call_type_detection["predicted"] == "BH":
            knbh_result = KNBHEvaluator().evaluate(features, transcript)
        else:
            knbh_result = KNSVEvaluator().evaluate(features, transcript)
        
        # Step 8: Calculate Total Score
        score = ScoreCalculator().calculate(
            kngt_result,
            knbh_result,
            weights
        )
        
        # Step 9: Generate Summary
        summary = SummaryGenerator().generate(transcript, score)
        
        # Step 10: Build Recommendations
        recommendations = Recommender().build(
            kngt_result["violations"] + knbh_result["violations"]
        )
        
        # Step 11: Map Scripts
        scripts = ScriptMapper().map(
            call_type_detection["predicted"],
            kngt_result["violations"] + knbh_result["violations"]
        )
        
        # Step 12: Generate Evidence
        evidence = EvidenceGenerator().generate(
            kngt_result["violations"] + knbh_result["violations"],
            transcript
        )
        
        # Step 13: Save Results
        save_results(job_id, {
            "call_type_detection": call_type_detection,
            "score": score,
            "summary": summary,
            "recommendations": recommendations,
            "scripts": scripts,
            "evidence": evidence
        })
        
        return {"status": "success", "score_id": score["id"]}
        
    except Exception as e:
        handle_error(job_id, e)
        return {"status": "failed", "error": str(e)}
```

---

## 6. DATABASE SCHEMA

### 6.1. Core Tables

#### Table: `calls`
```sql
CREATE TABLE calls (
    call_id VARCHAR(50) PRIMARY KEY,
    agent_id VARCHAR(50) NOT NULL,
    call_time TIMESTAMP NOT NULL,
    audio_url TEXT NOT NULL,
    duration FLOAT NOT NULL,
    
    -- Call Type Detection
    call_type_predicted VARCHAR(10) CHECK (call_type_predicted IN ('BH', 'CSKH')),
    call_type_confidence FLOAT CHECK (call_type_confidence BETWEEN 0 AND 1),
    call_type_signals JSONB,
    
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    
    INDEX idx_agent_id (agent_id),
    INDEX idx_call_time (call_time),
    INDEX idx_call_type (call_type_predicted)
);
```

#### Table: `call_scores`
```sql
CREATE TABLE call_scores (
    id SERIAL PRIMARY KEY,
    call_id VARCHAR(50) NOT NULL REFERENCES calls(call_id),
    job_id VARCHAR(50) UNIQUE NOT NULL,
    
    -- Scores
    total_score FLOAT NOT NULL CHECK (total_score BETWEEN 0 AND 10),
    label VARCHAR(20) NOT NULL CHECK (label IN ('Y·∫øu', 'Trung b√¨nh', 'Kh√°', 'T·ªët', 'Xu·∫•t s·∫Øc')),
    passed BOOLEAN NOT NULL,
    
    -- Weights used
    weight_kngt FLOAT NOT NULL,
    weight_knbh FLOAT NOT NULL,
    weights_method VARCHAR(50),  -- 'pure' | 'mixture'
    
    -- Group scores
    kngt_points FLOAT NOT NULL,
    kngt_max_points FLOAT NOT NULL,
    kngt_percentage FLOAT,
    
    knbh_points FLOAT NOT NULL,
    knbh_max_points FLOAT NOT NULL,
    knbh_percentage FLOAT,
    
    -- Summary
    summary_text TEXT NOT NULL,
    highlights JSONB,
    
    -- Processing metadata
    processing_time_ms INT,
    stt_duration_ms INT,
    evaluation_method VARCHAR(50),
    
    created_at TIMESTAMP DEFAULT NOW(),
    
    INDEX idx_call_id (call_id),
    INDEX idx_total_score (total_score),
    INDEX idx_label (label),
    INDEX idx_created_at (created_at)
);
```

#### Table: `criterion_evaluations`
```sql
CREATE TABLE criterion_evaluations (
    id SERIAL PRIMARY KEY,
    score_id INT NOT NULL REFERENCES call_scores(id),
    
    group_name VARCHAR(10) NOT NULL CHECK (group_name IN ('KNGT', 'KNBH', 'KNSV')),
    criterion_code VARCHAR(10) NOT NULL,  -- GRT, SR, NEED, ADV...
    criterion_name VARCHAR(100) NOT NULL,
    
    weight FLOAT NOT NULL,
    max_points FLOAT NOT NULL,
    earned_points FLOAT NOT NULL,
    
    violation_level VARCHAR(5) CHECK (violation_level IN ('OK', 'M1', 'M2', 'M3')),
    evidence JSONB,
    
    created_at TIMESTAMP DEFAULT NOW(),
    
    INDEX idx_score_id (score_id),
    INDEX idx_criterion_code (criterion_code),
    INDEX idx_violation_level (violation_level)
);
```

#### Table: `recommendations`
```sql
CREATE TABLE recommendations (
    id SERIAL PRIMARY KEY,
    score_id INT NOT NULL REFERENCES call_scores(id),
    
    priority VARCHAR(10) NOT NULL CHECK (priority IN ('low', 'medium', 'high')),
    category VARCHAR(10) NOT NULL,  -- KNGT | KNBH
    criterion VARCHAR(10) NOT NULL,
    
    message TEXT NOT NULL,
    actionable BOOLEAN DEFAULT true,
    
    created_at TIMESTAMP DEFAULT NOW(),
    
    INDEX idx_score_id (score_id),
    INDEX idx_priority (priority)
);
```

#### Table: `suggested_scripts`
```sql
CREATE TABLE suggested_scripts (
    id SERIAL PRIMARY KEY,
    score_id INT NOT NULL REFERENCES call_scores(id),
    
    script_id VARCHAR(50) NOT NULL,
    stage VARCHAR(50),
    text TEXT NOT NULL,
    when_to_use TEXT,
    
    INDEX idx_score_id (score_id),
    INDEX idx_script_id (script_id)
);
```

#### Table: `evidence`
```sql
CREATE TABLE evidence (
    id SERIAL PRIMARY KEY,
    score_id INT NOT NULL REFERENCES call_scores(id),
    criterion_code VARCHAR(10),
    
    evidence_type VARCHAR(30) NOT NULL,  -- metric_violation | criterion_violation | customer_impact
    
    timestamp_start FLOAT,
    timestamp_end FLOAT,
    text TEXT,
    
    -- For metric_violation (e.g., SR)
    wpm FLOAT,
    threshold VARCHAR(50),
    
    -- For criterion_violation
    reason TEXT,
    expected_behavior TEXT,
    
    severity VARCHAR(10) CHECK (severity IN ('low', 'medium', 'high')),
    customer_impact BOOLEAN DEFAULT false,
    
    created_at TIMESTAMP DEFAULT NOW(),
    
    INDEX idx_score_id (score_id),
    INDEX idx_criterion_code (criterion_code),
    INDEX idx_evidence_type (evidence_type)
);
```

### 6.2. Views for Reporting

```sql
-- View: Agent performance summary
CREATE VIEW agent_performance_summary AS
SELECT 
    c.agent_id,
    COUNT(*) as total_calls,
    AVG(cs.total_score) as avg_score,
    SUM(CASE WHEN cs.passed THEN 1 ELSE 0 END) as passed_count,
    SUM(CASE WHEN cs.label = 'Xu·∫•t s·∫Øc' THEN 1 ELSE 0 END) as excellent_count,
    AVG(cs.kngt_percentage) as avg_kngt_percentage,
    AVG(cs.knbh_percentage) as avg_knbh_percentage
FROM calls c
JOIN call_scores cs ON c.call_id = cs.call_id
WHERE c.created_at >= NOW() - INTERVAL '30 days'
GROUP BY c.agent_id;

-- View: Common violations by criterion
CREATE VIEW common_violations AS
SELECT 
    ce.criterion_code,
    ce.criterion_name,
    ce.group_name,
    ce.violation_level,
    COUNT(*) as violation_count,
    AVG(ce.earned_points / ce.max_points) as avg_score_ratio
FROM criterion_evaluations ce
WHERE ce.violation_level IN ('M1', 'M2', 'M3')
  AND created_at >= NOW() - INTERVAL '30 days'
GROUP BY ce.criterion_code, ce.criterion_name, ce.group_name, ce.violation_level
ORDER BY violation_count DESC;
```

---

## 7. API DESIGN

### 7.1. Main Endpoints

#### POST `/api/v1/calls/score`
**Description:** Submit a call for scoring (CASE 2)

**Request:**
```json
{
  "call_id": "CALL-2025-001",
  "agent_id": "AG001",
  "call_time": "2025-10-10T10:30:00Z",
  "audio_url": "s3://calls/CALL-2025-001.wav",
  "transcript": [...]
}
```

**Response (202 Accepted):**
```json
{
  "job_id": "JOB_67890",
  "status": "queued",
  "estimated_time": 25,
  "status_url": "/api/v1/jobs/JOB_67890"
}
```

---

#### GET `/api/v1/calls/{call_id}/score`
**Description:** Get call scoring result

**Response (200 OK):**
```json
{
  "call_id": "CALL-2025-001",
  "call_type_detection": {...},
  "score": {...},
  "summary": {...},
  "recommendations": [...],
  "suggested_scripts": [...],
  "evidence": [...],
  "metadata": {...}
}
```

---

#### GET `/api/v1/agents/{agent_id}/performance`
**Description:** Get agent performance summary

**Query Parameters:**
- `start_date` (required)
- `end_date` (required)
- `call_type` (optional: BH | CSKH)

**Response (200 OK):**
```json
{
  "agent_id": "AG001",
  "period": {
    "start": "2025-09-01",
    "end": "2025-10-01"
  },
  "summary": {
    "total_calls": 150,
    "avg_score": 7.8,
    "passed_rate": 0.92,
    "label_distribution": {
      "Xu·∫•t s·∫Øc": 20,
      "T·ªët": 70,
      "Kh√°": 40,
      "Trung b√¨nh": 15,
      "Y·∫øu": 5
    }
  },
  "kngt_avg": 7.5,
  "knbh_avg": 8.0,
  "common_violations": [
    {
      "criterion": "SR",
      "count": 25,
      "avg_level": "M1"
    },
    {
      "criterion": "NEED",
      "count": 18,
      "avg_level": "M2"
    }
  ],
  "trend": "improving"
}
```

---

## 8. CALL TYPE DETECTION (AUDIO-ONLY)

### 8.1. Detailed Implementation

**File:** `services/call_type_detector.py`

```python
import re
from typing import Dict, List
import numpy as np

class CallTypeDetector:
    """
    Detect call type (BH/CSKH) from audio/transcript only
    
    No CRM data required - pure audio-based detection
    """
    
    # Keywords dictionary
    BH_KEYWORDS = [
        "g√≥i", "b·∫£o hi·ªÉm", "∆∞u ƒë√£i", "khuy·∫øn m√£i", "gi√°", "ph√≠",
        "quy·ªÅn l·ª£i", "s·∫£n ph·∫©m", "d·ªãch v·ª•", "mua", "ƒëƒÉng k√Ω",
        "chi·∫øt kh·∫•u", "thanh to√°n", "h·ª£p ƒë·ªìng", "cam k·∫øt"
    ]
    
    CSKH_KEYWORDS = [
        "l·ªói", "kh√¥ng ho·∫°t ƒë·ªông", "khi·∫øu n·∫°i", "h·ªó tr·ª£", "b√°o l·ªói",
        "fix", "s·ª≠a", "kh·∫Øc ph·ª•c", "v·∫•n ƒë·ªÅ", "tr·ª•c tr·∫∑c",
        "kh√¥ng d√πng ƒë∆∞·ª£c", "b·ªã l·ªói", "kh√¥ng th·ªÉ", "help", "gi√∫p"
    ]
    
    def detect(self, transcript: List[Dict], audio_features: Dict = None) -> Dict:
        """
        Main detection method
        
        Args:
            transcript: Full transcript with diarization
            audio_features: Optional audio features (sentiment, etc.)
        
        Returns:
            {
                "predicted": "BH" | "CSKH",
                "confidence": float,
                "signals": {...}
            }
        """
        # Focus on first 60 seconds
        first_60s = self._get_first_n_seconds(transcript, 60)
        
        # 1. Keyword analysis
        keyword_signal = self._analyze_keywords(first_60s)
        
        # 2. Interaction pattern
        pattern_signal = self._analyze_interaction_pattern(transcript[:5])
        
        # 3. Sentiment trend
        sentiment_signal = self._analyze_sentiment(first_60s, audio_features)
        
        # 4. Agent action analysis
        action_signal = self._analyze_agent_actions(first_60s)
        
        # Combine signals
        prob_bh = self._combine_signals(
            keyword_signal,
            pattern_signal,
            sentiment_signal,
            action_signal
        )
        
        predicted = "BH" if prob_bh > 0.5 else "CSKH"
        confidence = max(prob_bh, 1 - prob_bh)
        
        return {
            "predicted": predicted,
            "confidence": confidence,
            "signals": {
                "keyword": keyword_signal,
                "pattern": pattern_signal,
                "sentiment": sentiment_signal,
                "action": action_signal,
                "prob_bh": prob_bh
            },
            "method": "audio_only"
        }
    
    def _get_first_n_seconds(self, transcript: List[Dict], n: int) -> List[Dict]:
        """Get segments in first N seconds"""
        return [seg for seg in transcript if seg["end"] <= n]
    
    def _analyze_keywords(self, segments: List[Dict]) -> Dict:
        """Analyze keywords to determine call type"""
        text_combined = " ".join([seg["text"].lower() for seg in segments])
        
        bh_count = sum(1 for kw in self.BH_KEYWORDS if kw in text_combined)
        cskh_count = sum(1 for kw in self.CSKH_KEYWORDS if kw in text_combined)
        
        total = bh_count + cskh_count
        if total == 0:
            score = 0.5  # Neutral
        else:
            score = bh_count / total
        
        return {
            "bh_keyword_count": bh_count,
            "cskh_keyword_count": cskh_count,
            "score_bh": score,
            "weight": 0.4
        }
    
    def _analyze_interaction_pattern(self, first_segments: List[Dict]) -> Dict:
        """
        Analyze who speaks first and interaction flow
        
        BH: Agent typically leads (proactive)
        CSKH: Customer typically opens with problem
        """
        if not first_segments:
            return {"score_bh": 0.5, "weight": 0.2}
        
        first_speaker = first_segments[0]["speaker"]
        
        # Count agent vs customer turns in first 3 exchanges
        agent_turns = sum(1 for s in first_segments[:3] if s["speaker"] == "AGENT")
        customer_turns = sum(1 for s in first_segments[:3] if s["speaker"] == "CUSTOMER")
        
        # BH: Agent leads, more agent turns
        # CSKH: Customer often leads with complaint
        if first_speaker == "AGENT" and agent_turns >= customer_turns:
            score = 0.7  # Likely BH
        elif first_speaker == "CUSTOMER" and customer_turns > agent_turns:
            score = 0.3  # Likely CSKH
        else:
            score = 0.5
        
        return {
            "first_speaker": first_speaker,
            "agent_turns": agent_turns,
            "customer_turns": customer_turns,
            "score_bh": score,
            "weight": 0.2
        }
    
    def _analyze_sentiment(self, segments: List[Dict], audio_features: Dict = None) -> Dict:
        """
        Analyze sentiment trend
        
        BH: neutral ‚Üí positive (persuasion)
        CSKH: negative/frustrated ‚Üí neutral/resolved
        """
        if audio_features and "sentiment_trend" in audio_features:
            trend = audio_features["sentiment_trend"]
        else:
            # Simple heuristic based on text
            first_half = segments[:len(segments)//2]
            second_half = segments[len(segments)//2:]
            
            first_sentiment = self._simple_sentiment(first_half)
            second_sentiment = self._simple_sentiment(second_half)
            
            if first_sentiment < 0 and second_sentiment > first_sentiment:
                trend = "negative_to_neutral"  # Typical CSKH
            elif first_sentiment >= 0 and second_sentiment > first_sentiment:
                trend = "neutral_to_positive"  # Typical BH
            else:
                trend = "mixed"
        
        if trend == "neutral_to_positive":
            score = 0.7  # BH
        elif trend == "negative_to_neutral":
            score = 0.3  # CSKH
        else:
            score = 0.5
        
        return {
            "trend": trend,
            "score_bh": score,
            "weight": 0.2
        }
    
    def _analyze_agent_actions(self, segments: List[Dict]) -> Dict:
        """
        Analyze what agent is doing
        
        BH: Introducing products, asking about needs, offering deals
        CSKH: Diagnosing issues, providing solutions, creating tickets
        """
        agent_text = " ".join([
            seg["text"].lower() 
            for seg in segments 
            if seg["speaker"] == "AGENT"
        ])
        
        # BH actions
        bh_patterns = [
            r"(gi·ªõi thi·ªáu|t∆∞ v·∫•n|s·∫£n ph·∫©m|g√≥i|quy·ªÅn l·ª£i)",
            r"(anh.*quan t√¢m|anh.*c·∫ßn|anh.*mu·ªën)",
            r"(∆∞u ƒë√£i|khuy·∫øn m√£i|chi·∫øt kh·∫•u)"
        ]
        
        # CSKH actions
        cskh_patterns = [
            r"(v·∫•n ƒë·ªÅ.*g√¨|l·ªói.*g√¨|khi·∫øu n·∫°i.*g√¨)",
            r"(em.*ki·ªÉm tra|em.*h·ªó tr·ª£|em.*fix)",
            r"(ticket|phi·∫øu|ghi nh·∫≠n)"
        ]
        
        bh_matches = sum(1 for p in bh_patterns if re.search(p, agent_text))
        cskh_matches = sum(1 for p in cskh_patterns if re.search(p, agent_text))
        
        total = bh_matches + cskh_matches
        if total == 0:
            score = 0.5
        else:
            score = bh_matches / total
        
        return {
            "bh_action_count": bh_matches,
            "cskh_action_count": cskh_matches,
            "score_bh": score,
            "weight": 0.2
        }
    
    def _combine_signals(
        self,
        keyword_signal: Dict,
        pattern_signal: Dict,
        sentiment_signal: Dict,
        action_signal: Dict
    ) -> float:
        """
        Combine all signals using weighted average
        """
        signals = [keyword_signal, pattern_signal, sentiment_signal, action_signal]
        
        weighted_sum = sum(s["score_bh"] * s["weight"] for s in signals)
        total_weight = sum(s["weight"] for s in signals)
        
        prob_bh = weighted_sum / total_weight
        
        return prob_bh
    
    def _simple_sentiment(self, segments: List[Dict]) -> float:
        """
        Simple sentiment analysis based on keywords
        Returns: -1 (negative) to 1 (positive)
        """
        text = " ".join([seg["text"].lower() for seg in segments])
        
        positive_words = ["t·ªët", "c·∫£m ∆°n", "ƒë·ªìng √Ω", "·ªïn", "ƒë∆∞·ª£c", "vui"]
        negative_words = ["l·ªói", "kh√¥ng", "khi·∫øu n·∫°i", "t·ªá", "k√©m", "th·∫•t v·ªçng"]
        
        pos_count = sum(1 for w in positive_words if w in text)
        neg_count = sum(1 for w in negative_words if w in text)
        
        total = pos_count + neg_count
        if total == 0:
            return 0.0
        
        return (pos_count - neg_count) / total
```

---

## 9. SPEECH RATE EVALUATION (SR - KNGT)

### 9.1. Integration v·ªõi KNGT

**Speech Rate (SR)** l√† 1 trong 7 ti√™u ch√≠ c·ªßa KNGT, chi·∫øm:
- **BH:** 0.08 √ó 4.0 = 0.32 ƒëi·ªÉm
- **CSKH:** 0.10 √ó 7.0 = 0.70 ƒëi·ªÉm

### 9.2. Implementation

**File:** `services/kngt/speech_rate_evaluator.py`

```python
from typing import Dict, List, Optional

class SpeechRateEvaluator:
    """
    Evaluate Speech Rate criterion (SR) in KNGT
    
    S·ª≠ d·ª•ng logic ƒë√£ thi·∫øt k·∫ø trong:
    - 11_BOOTSTRAP_STRATEGY_NO_BASELINE.md
    - BAO_CAO_NGAT_KHONG_DUNG_BASELINE.md
    """
    
    THRESHOLDS = {
        "BH": {
            "very_slow": 100,
            "slow": 130,
            "fast": 180,
            "very_fast": 220
        },
        "CSKH": {
            "very_slow": 90,
            "slow": 120,
            "fast": 170,
            "very_fast": 210
        }
    }
    
    def evaluate(
        self,
        segments: List[Dict],
        call_type: str,
        transcript: List[Dict]
    ) -> Optional[Dict]:
        """
        Evaluate speech rate
        
        Returns None if OK, otherwise returns violation dict
        """
        # B∆∞·ªõc 1-8: T√≠nh WPM cho t·ª´ng segment (nh∆∞ thi·∫øt k·∫ø)
        wpm_segments = self._calculate_wpm_segments(segments)
        wpm_values = [s["wpm"] for s in wpm_segments]
        
        # B∆∞·ªõc 9: Ph√°t hi·ªán Customer Impact
        customer_impacts = self._detect_customer_impact(transcript)
        
        # B∆∞·ªõc 10: ƒê√°nh gi√° (KH√îNG C·∫¶N BASELINE)
        violation = self._evaluate_cold_start(
            wpm_values,
            call_type,
            customer_impacts
        )
        
        if violation["violation_level"] == "OK":
            return None  # No violation
        
        # B∆∞·ªõc 11: T·∫°o evidence
        evidence = self._generate_evidence(
            wpm_segments,
            customer_impacts,
            call_type
        )
        
        return {
            "code": "SR",
            "name": "T·ªëc ƒë·ªô n√≥i & r√µ r√†ng",
            "level": violation["violation_level"],
            "evidence": {
                "median_wpm": np.median(wpm_values),
                "p90_wpm": np.percentile(wpm_values, 90),
                "total_segments": len(wpm_values),
                "customer_impact_count": customer_impacts["repeat_requests"],
                "violated_segments": evidence["metric_violations"],
                "customer_complaints": evidence["customer_impacts"]
            },
            "recommendation": self._get_recommendation(
                violation["violation_level"],
                np.median(wpm_values),
                call_type
            )
        }
    
    def _calculate_wpm_segments(self, segments: List[Dict]) -> List[Dict]:
        """Calculate WPM for each segment"""
        # Implementation t·ª´ 11_BOOTSTRAP_STRATEGY_NO_BASELINE.md
        # ...
        pass
    
    def _detect_customer_impact(self, transcript: List[Dict]) -> Dict:
        """Detect customer complaints about speech rate"""
        # Implementation t·ª´ 11_BOOTSTRAP_STRATEGY_NO_BASELINE.md
        # ...
        pass
    
    def _evaluate_cold_start(
        self,
        wpm_values: List[float],
        call_type: str,
        customer_impacts: Dict
    ) -> Dict:
        """
        Evaluate using absolute thresholds (no baseline)
        
        Priority:
        1. Customer Impact (highest)
        2. Segment violation ratio
        """
        thresholds = self.THRESHOLDS[call_type]
        
        # ∆Øu ti√™n 1: Customer Impact
        repeat_count = customer_impacts["repeat_requests"]
        if repeat_count >= 3:
            return {
                "violation_level": "M2",
                "reason": f"KH y√™u c·∫ßu nh·∫Øc l·∫°i {repeat_count} l·∫ßn"
            }
        
        # ∆Øu ti√™n 2: T·ª∑ l·ªá segments vi ph·∫°m
        total = len(wpm_values)
        very_slow = sum(1 for w in wpm_values if w < thresholds["very_slow"])
        very_fast = sum(1 for w in wpm_values if w > thresholds["very_fast"])
        slow = sum(1 for w in wpm_values if thresholds["very_slow"] <= w < thresholds["slow"])
        fast = sum(1 for w in wpm_values if thresholds["fast"] < w <= thresholds["very_fast"])
        
        very_slow_ratio = very_slow / total
        very_fast_ratio = very_fast / total
        outlier_ratio = (slow + fast) / total
        
        # M3: Very severe
        if very_slow_ratio >= 0.20 or very_fast_ratio >= 0.20:
            return {
                "violation_level": "M3",
                "reason": f"20%+ segments qu√° nhanh/ch·∫≠m"
            }
        
        # M2: Severe
        if very_slow_ratio >= 0.10 or very_fast_ratio >= 0.10:
            return {
                "violation_level": "M2",
                "reason": f"10%+ segments qu√° nhanh/ch·∫≠m"
            }
        
        # M1: Minor
        if outlier_ratio >= 0.25 or repeat_count >= 2:
            return {
                "violation_level": "M1",
                "reason": f"25%+ segments h∆°i l·ªách"
            }
        
        return {"violation_level": "OK"}
    
    def _get_recommendation(
        self,
        level: str,
        median_wpm: float,
        call_type: str
    ) -> str:
        """Generate actionable recommendation"""
        thresholds = self.THRESHOLDS[call_type]
        
        if median_wpm > thresholds["fast"]:
            return (
                f"Gi·∫£m t·ªëc ƒë·ªô xu·ªëng {thresholds['slow']}-{thresholds['fast']} wpm "
                f"khi tr√¨nh b√†y th√¥ng tin quan tr·ªçng. Xen k·∫Ω c√¢u ng·∫Øn v√† ki·ªÉm tra "
                f"s·ª± hi·ªÉu c·ªßa KH b·∫±ng c√¢u h·ªèi: 'Anh c√≥ th·∫Øc m·∫Øc ƒëi·ªÉm n√†o kh√¥ng ·∫°?'"
            )
        elif median_wpm < thresholds["slow"]:
            return (
                f"TƒÉng t·ªëc ƒë·ªô l√™n {thresholds['slow']}-{thresholds['fast']} wpm "
                f"ƒë·ªÉ duy tr√¨ nƒÉng l∆∞·ª£ng cu·ªôc g·ªçi. Tr√°nh im l·∫∑ng qu√° l√¢u gi·ªØa c√°c c√¢u."
            )
        else:
            return (
                f"Duy tr√¨ t·ªëc ƒë·ªô ·ªïn ƒë·ªãnh trong kho·∫£ng "
                f"{thresholds['slow']}-{thresholds['fast']} wpm. "
                f"ƒêi·ªÅu ch·ªânh linh ho·∫°t theo ph·∫£n ·ª©ng c·ªßa KH."
            )
```

---

## 10. CASE 1: CRM COMPLIANCE (Tham chi·∫øu)

### 10.1. Scope & Integration

**CASE 1** (UC09) x·ª≠ l√Ω **NTT (Nh·∫≠p th√¥ng tin)** - 10% ƒëi·ªÉm t·ªïng:
- Ki·ªÉm tra Agent c√≥ c·∫≠p nh·∫≠t CRM/ticket ƒë√∫ng h·∫°n
- Ph√°t hi·ªán vi ph·∫°m M1/M2/M3
- G·ª≠i nh·∫Øc nh·ªü v√† theo d√µi kh·∫Øc ph·ª•c
- **KH√îNG** thu·ªôc CASE 2, nh∆∞ng ƒëi·ªÉm NTT ƒë∆∞·ª£c c·ªông v√†o t·ªïng

### 10.2. Integration Point

```python
def calculate_final_score_with_ntt(
    case2_score: Dict,  # KNGT + KNBH t·ª´ CASE 2
    ntt_score: Dict     # NTT t·ª´ CASE 1 (UC09)
) -> Dict:
    """
    Combine CASE 2 (KNGT+KNBH) with CASE 1 (NTT)
    
    Total = CASE2 (9.0) + NTT (1.0) = 10.0
    """
    # CASE 2: KNGT + KNBH = 90% ƒëi·ªÉm (9.0/10)
    kngt_points = case2_score["kngt_points"]
    knbh_points = case2_score["knbh_points"]
    case2_total = kngt_points + knbh_points  # Max 9.0
    
    # CASE 1: NTT = 10% ƒëi·ªÉm (1.0/10)
    ntt_points = ntt_score["points"]  # Max 1.0
    
    # Total
    total_score = case2_total + ntt_points
    
    return {
        "total_score": total_score,
        "breakdown": {
            "KNGT": kngt_points,
            "KNBH": knbh_points,
            "NTT": ntt_points
        },
        "label": get_label(total_score),
        "passed": total_score >= 5.0
    }
```

---

## 11. PERFORMANCE & SCALABILITY

### 11.1. Performance Targets (Tu√¢n th·ªß UC01)

| Metric | Target | Measurement |
|--------|--------|-------------|
| **MAE ƒëi·ªÉm t·ªïng** | ‚â§ 1.0 | vs QA th·ªß c√¥ng tr√™n 100 calls |
| **F1 ph√°t hi·ªán M2/M3** | ‚â• 0.8 | Precision & Recall |
| **Latency sinh b√°o c√°o** | ‚â§ 5s | Kh√¥ng t√≠nh STT |
| **STT duration** | ~30% audio length | 5 ph√∫t ‚Üí ~90s |
| **Call Type accuracy** | ‚â• 85% | Validation set |

### 11.2. Monitoring (Prometheus)

```python
# Business metrics
from prometheus_client import Counter, Histogram, Gauge

# Call Type Detection
calltype_detection_accuracy = Gauge(
    'calltype_detection_accuracy',
    'Call type detection accuracy'
)

calltype_confidence = Histogram(
    'calltype_confidence',
    'Call type confidence distribution'
)

# Scoring metrics
score_mae = Gauge(
    'score_mae',
    'Mean Absolute Error vs QA manual',
    ['call_type']
)

violation_f1 = Gauge(
    'violation_f1_score',
    'F1 score for M2/M3 detection',
    ['criterion']
)

# Performance metrics
scoring_latency = Histogram(
    'scoring_latency_seconds',
    'Time to generate score (excluding STT)',
    ['call_type']
)
```

---

## 12. DEPLOYMENT & OPERATIONS

### 12.1. Docker Compose (Development)

```yaml
version: '3.8'

services:
  # API Service
  api:
    build: ./services/api
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/qa_scoring
      - REDIS_URL=redis://redis:6379/0
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
    depends_on:
      - postgres
      - redis
      - rabbitmq
  
  # Celery Worker (CASE 2)
  worker-case2:
    build: ./services/worker
    command: celery -A tasks worker --loglevel=info --queues=case2
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/qa_scoring
      - REDIS_URL=redis://redis:6379/0
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
    depends_on:
      - postgres
      - redis
      - rabbitmq
  
  # STT Service
  stt:
    build: ./services/stt
    ports:
      - "8001:8000"
    volumes:
      - ./models:/models
  
  # PostgreSQL
  postgres:
    image: postgres:14
    environment:
      POSTGRES_DB: qa_scoring
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  # Redis
  redis:
    image: redis:7
    ports:
      - "6379:6379"
  
  # RabbitMQ
  rabbitmq:
    image: rabbitmq:3.11-management
    ports:
      - "5672:5672"
      - "15672:15672"

volumes:
  postgres_data:
```

---

## PH·ª§ L·ª§C

### A. Tham chi·∫øu t√†i li·ªáu

Thi·∫øt k·∫ø n√†y tu√¢n th·ªß:
- ‚úÖ `00_Master_Spec.md` - Master specification
- ‚úÖ `UC01_Call_Scoring_SPEC.md` - Use case chi ti·∫øt
- ‚úÖ `02_Sequence_UC01_Call_Scoring.md` - Sequence diagram
- ‚úÖ `05_Scoring_Criteria_Decomposition.md` - Ti√™u ch√≠ ch·∫•m ƒëi·ªÉm
- ‚úÖ `11_BOOTSTRAP_STRATEGY_NO_BASELINE.md` - Speech Rate strategy
- ‚úÖ `BAO_CAO_NGAT_KHONG_DUNG_BASELINE.md` - Speech Rate implementation

### B. Glossary

- **KNGT:** K·ªπ nƒÉng giao ti·∫øp (Communication Skills)
- **KNBH:** K·ªπ nƒÉng b√°n h√†ng (Sales Skills)
- **KNSV:** K·ªπ nƒÉng d·ªãch v·ª• (Service Skills) - CSKH variant
- **NTT:** Nh·∫≠p th√¥ng tin (CRM Data Entry)
- **CTA:** Call-to-Action
- **BH:** B√°n h√†ng (Sales)
- **CSKH:** ChƒÉm s√≥c kh√°ch h√†ng (Customer Service)
- **œÑ (tau):** Ng∆∞·ª°ng confidence cho call type (0.75)

---

**Document Version:** 2.0  
**Last Updated:** 10/10/2025  
**Status:** Draft - Ready for Review